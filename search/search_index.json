{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>Welcome to the AI-on-the-edge-device project!</p> <p>This is the documentation. For the source code, please head to github.com/jomjol/AI-on-the-edge-device.</p> <p>Artificial intelligence based systems have been established in our everyday lives. Just think of speech or image recognition. Most of the systems rely on either powerful processors or a direct connection to the cloud for doing the calculations up there. With the increasing power of modern processors the AI systems are coming closer to the end user - which is usually called edge computing. Here this edge computing is brought into a practice-oriented example, where a AI network is implemented on a ESP32 device so: AI on the edge.</p>"},{"location":"#key-features","title":"Key features","text":"<ul> <li>Tensorflow Lite (TFlite) integration - including easy to use wrapper</li> <li>Inline image processing (feature detection, alignment, ROI extraction)</li> <li>Small and cheap device (3x4.5x2 cm\u00b3, &lt; 10 EUR)</li> <li>Camera and illumination integrated</li> <li>Web surface to administrate and control</li> <li>OTA-Interface to update directly through the web interface</li> <li>Full integration into Home Assistant</li> <li>Support for Influx DB 1 and 2</li> <li>MQTT</li> <li>REST API</li> </ul>"},{"location":"#idea","title":"Idea","text":""},{"location":"#hardware","title":"Hardware","text":""},{"location":"#web-interface","title":"Web interface","text":""},{"location":"#configuration-interface","title":"Configuration Interface","text":"<p>Have fun in studying the new possibilities and ideas</p> <p>This is about image recognition and digitalization, done totally on a cheap ESP32 board using artificial intelligence in form of convolutional neural networks (CNN). Everything, from image capture (OV2640), image preprocessing (auto alignment, ROI identification) all the way down to the image recognition (CNN structure) and result plausibility is done on a cheap 10 EUR device.</p> <p>This all is integrated in an easy to do setup and use environment, taking care for all the background processing and handling, including regular job scheduler. The user interface is an integrated web server, that can be easily adjusted and offers the data as an API in different options.</p> <p>The task to be demonstrated here is an automated readout of an analog water meter. The water consumption is to be recorded within a house automatization and the water meter is totally analog without any electronic interface. Therefore, the task is solved by regularly taking an image of the water meter and digitizing the reading.</p> <p>There are two types of CNN implemented, a classification network for reading the digital numbers and a single output network for digitalize the analog pointers for the sub digit readings.</p> <p>This project is an evolution of the water-meter-system-complete, which uses ESP32-CAM just for taking the image and a 1GB-Docker image to run the neural network's backbone. Here everything is integrated in an ESP32-CAM module with 8MB of RAM and a SD card as data storage.</p>"},{"location":"#additional-tutorials","title":"Additional Tutorials","text":"<p>A lot of people created useful Youtube videos which might help you getting started. Here a small selection:</p> <ul> <li>youtube.com/watch?v=HKBofb1cnNc</li> <li>youtube.com/watch?v=yyf0ORNLCk4</li> <li>youtube.com/watch?v=XxmTubGek6M</li> <li>youtube.com/watch?v=mDIJEyElkAU</li> <li>youtube.com/watch?v=SssiPkyKVVs</li> <li>youtube.com/watch?v=MAHE_QyHZFQ</li> <li>youtube.com/watch?v=Uap_6bwtILQ</li> </ul>"},{"location":"Additional-Information/","title":"Additional Information","text":"<p>The following links point to additional information in other repos:</p>"},{"location":"Additional-Information/#digits","title":"Digits","text":"<ul> <li>Training and using a neural network to readout the value of a digital counter</li> <li>Training the CNN neural network</li> </ul>"},{"location":"Additional-Information/#analog","title":"Analog","text":"<ul> <li>Training and using a neural network to read out the value of an analog display</li> <li>Training the CNN neural network</li> </ul>"},{"location":"Alignment/","title":"Alignment References","text":"<p>The alignment references are used in every round to re-align the taken image to the reference coordinates.  Two alignment structures must be defined and the taken image then in each round is shifted and rotated according to their position with the target to be in exactly the same position as the reference image.</p> <p>Note</p> <p>The alignment structures needs to be unique and have a good contrast.  It is advised to have them as far apart as possible.</p>"},{"location":"Alignment/#precondition","title":"Precondition","text":"<p>Please make sure to have setup your camera properly and taken a good Reference Image.</p>"},{"location":"Alignment/#define-two-reference-images","title":"Define two Reference Images","text":"<p>You can switch between this two marks with <code>(1)</code>.</p> <p>Then define the reference area in the image by either directly drag and drop with the mouse or use the input boxes below. To apply the currently marked image part you need to push <code>\"Update Reference\" (2)</code>. </p> <p>In some cases it might be useful to use a reference with a higher contrast. This can be achieved by pushing <code>Enhance Contrast\" (3)</code>. The result will be calculated on the ESP32 - so be a bit patient, before you see it active.</p> <p>To save push <code>\"Save to config.ini\" (4)</code>.</p> <p>Note</p> <p>A reboot is not required at this point of time.</p> <p>As next you should define the Digit and Analog ROIs.</p>"},{"location":"Best-Practice/","title":"Best Practice","text":"<p>This page shows some best practices:</p>"},{"location":"Best-Practice/#camera-placement","title":"Camera Placement","text":"<ul> <li>Move the Camera as close as possible (~4cm), this will help get rid of reflections.   -&gt; focus can be adjusted by turning the outer black ring of the camera.</li> <li>If the LED reflections are too strong, put tape over the LED to diffuse the light</li> <li>Change the ImageSize to QVGA under \"Expert mode\" configuration when close enough, this will be faster and is often good enough for digital recognition.</li> </ul>"},{"location":"Best-Practice/#reflections","title":"Reflections","text":"<ul> <li>Try to get rid of the reflections by rotating the camera, so that the reflections are at positions, where no number is.</li> <li>By using the external LED option, you can place WS2812 LEDs freely away from the main axis.</li> <li>Users report, that a handy cover foil could also help</li> </ul>"},{"location":"Best-Practice/#post-processing","title":"Post-processing","text":"<ul> <li>Filter out the Number \"9\", as \"3\" will often be misread for a \"9\" and void every number between 3 and 9 due to it being negative flow.</li> <li>Split the readings into two, while the decimal numbers might move to fast to be recognized, at least the slower moving part will produce a correct reading. -&gt; keep in mind that the offset needs to be adjusted, a.e if you have a comma reading of \"3\", it needs to become \"0.3\". This can be done wherever the data ends up being sent, like home assistant using sensor templates.</li> <li>If you are using a low resolution and only digital mode, processing can often be done in &lt;1 minute. Check the logs to confirm how fast it is and then set the interval accordingly under \"Expert mode\" in configuration, as the normal mode will lock you to 3+ minutes.</li> </ul>"},{"location":"Build-Instructions/","title":"Build the Project","text":"<p>See README.md in the main repo.</p>"},{"location":"Choosing-the-Model/","title":"Model Selection","text":"<p>Notes</p> <p>See Neural Network Types for additional details.</p> <p>In the Graphical Configuration Page, you can choose different models depending on your needs.</p> <p>This page tries to help you on which model to select. For more technical/deeper explanations have a look on Neural-Network-Types.</p>"},{"location":"Choosing-the-Model/#digit-models","title":"Digit Models","text":"<p>For digits on water meters, gas-meters or power meters you can select between two main types of models.</p>"},{"location":"Choosing-the-Model/#dig-class11","title":"dig-class11","text":"<p>This model can recognize full digits. It was the first model version. All intermediate states shown a \"N\" for not a number. But in post process it uses older values to fill up the \"N\" values if possible.</p> <p></p> <p>It's possibly a good fallback, if <code>dig-cont/dig-class100</code> results are not good.</p>"},{"location":"Choosing-the-Model/#main-features","title":"Main features","text":"<ul> <li>well suited for LCD digits</li> <li>the ExtendedResolution option is not supported. (Only in conjunction with ana-class100 / ana-cont)</li> </ul>"},{"location":"Choosing-the-Model/#dig-class100-dig-cont","title":"dig-class100 / dig-cont","text":"<p>These models are used to get a continuous reading with intermediate states. To see what the models are doing, you can go to the Recognition page.</p> <p></p>"},{"location":"Choosing-the-Model/#main-features_1","title":"Main features","text":"<ul> <li>suitable for all digit displays.</li> <li>Advantage over dig-class11 that results continue to be calculated in the transition between digits.</li> <li>With the ExtendedResolution option, higher accuracy is possible by adding another digit.</li> </ul> <p>Look here for a list of digit images used for the training.</p>"},{"location":"Choosing-the-Model/#dig-class100-vs-dig-cont","title":"dig-class100 vs. dig-cont","text":"<p>The difference is in the internal processing. </p> <p>The dig-class100 is a standard classification model. Each tenth step is an output. </p> <p>dig-cont uses two outputs and arctangent to get the result. You see very complicated. </p> <p>Try both models on your device and take the one that gives you the best results.</p>"},{"location":"Choosing-the-Model/#analog-pointer-models","title":"Analog pointer models","text":""},{"location":"Choosing-the-Model/#ana-class100-ana-cont","title":"ana-class100 / ana-cont","text":"<p>For pointers on water meters use the analog models. You can only choose between ana-class100 and ana-cont. Both do mainly the same.</p> <p></p>"},{"location":"Choosing-the-Model/#main-features_2","title":"Main features","text":"<ul> <li>for all analogue pointers, especially for water meters.</li> <li>With the ExtendedResolution option, higher accuracy is possible by adding another digit.</li> </ul> <p>Look here for a list of pointer images used for the training</p>"},{"location":"Choosing-the-Model/#ana-class100-vs-ana-cont","title":"ana-class100 vs. ana-cont","text":"<p>The difference is in the internal processing.</p> <p>Take the one that gives you the best results. Both models learn from the same data.</p>"},{"location":"Choosing-the-Model/#different-types-of-models-normal-vs-quantized","title":"Different types of models (normal vs. quantized)","text":"<p>The normally trained network is calculating with internal floating point numbers. The saving of floating point numbers naturally takes more space than an integer type. Often the increased accuracy is not needed. Therefore there is the option, to \"quantize\" a neural network. In this case the internal values are rescaled to integer values, which is called \"quantization\". The stored tflite files are usually much smaller and runs faster on the edgeAI-device. Usually the models are distrusted therefore in both versions. They can be distinguished by a \"-q\" at the end of the logfile.</p>"},{"location":"Choosing-the-Model/#example","title":"Example:","text":"Type Name Normal <code>dig-cont_0610_s3.tflite</code> Quantized <code>dig-cont_0610_s3-q.tflite</code>"},{"location":"Configuration/","title":"Graphical Configuration","text":"<p>Most of the settings can be modified on the Settings page:</p> <p></p> <p>It can be reached via the menu <code>Settings &gt; Configuration</code>.</p> <p>Note</p> <ul> <li>To activate the changes, the device needs to be restarted after saving the changes.</li> <li>Most of the commands need processing on the ESP32 device. This is not very fast - so please be patient.</li> </ul> <p>All parameters are documented on the Parameters page and as tooltips on the config page.</p>"},{"location":"Configuration/#expert-parameters","title":"Expert Parameters","text":"<p>Some parameters are treated as Expert Parameters and are hidden by default. Tick the checkbox in the top left corner to enable them:</p> <p> </p> <p>The Expert Parameters then will be shown with a red background:  </p>"},{"location":"Configuration/#manual-editing-of-the-config-file","title":"Manual Editing of the Config File","text":"<p>Even more configuration parameters can be edited manually in the <code>config.ini</code>:</p> <p> </p> <p>To edit the <code>config.ini</code> file directly, click on the <code>Edit Config.ini directly</code> button.</p>"},{"location":"Configuration/#background-information","title":"Background Information","text":"<p>Note</p> <p>You do not need to understand this! But you might be interested in it.</p> <p>The principle is very simple and can most easily be described as a flow of processing steps. Each step has a dedicated parameter description in the <code>config.ini</code>, which is indicated by brackets <code>[name_of_step]</code>. The steps are processed in the order written in the config file. That means, that you first have to describe the image taking, then the aligning and cutting and only after that you can start to config a neural network. The last step is the post processing.</p>"},{"location":"Configuration/#processing-steps-overview","title":"Processing steps - Overview","text":"<p>In the following you get a short overview over the available steps. This order is also the suggested order for the processing flow. Single steps can be left out, if not needed (e.g. omit the analog part, if only digits are present)</p>"},{"location":"Configuration/#1-takeimage","title":"1. <code>[TakeImage]</code>","text":"<p>This steps parametrises the taking of the image by the ESP32-CAM. Size, quality and storage for logging and debugging can be set.</p>"},{"location":"Configuration/#2-alignment","title":"2. <code>[Alignment]</code>","text":"<p>Image preprocessing, including image alignment with reference images</p>"},{"location":"Configuration/#3-digits","title":"3. <code>[Digits]</code>","text":"<p>Neural network evaluation of an image for digits. The neural network is defined by a tflite formatted file and the output is a number between 0 .. 9 or NaN (if image is not unique enough)</p>"},{"location":"Configuration/#4-analog","title":"4. <code>[Analog]</code>","text":"<p>Neural network evaluation of analog counter. The neural network is defined by a tflite formatted file and the output is a number between 0.0 .. 9.9, representing the position of the pointer.</p>"},{"location":"Configuration/#5-postprocessing","title":"5. <code>[PostProcessing]</code>","text":"<p>Summarized the individually converted pictures to the overall result. It also implements some error corrections and consistency checks to filter wrong reading.</p> <p>For more details look at Correction Algorithm).</p>"},{"location":"Configuration/#6-mqtt","title":"6. <code>[MQTT]</code>","text":"<p>Transfer of the readings to a MQTT server.</p>"},{"location":"Configuration/#7-autotimer","title":"7. <code>[AutoTimer]</code>","text":"<p>Configuration of the automated flow start at the start up of the ESP32. </p>"},{"location":"Configuration/#8-debug","title":"8. <code>[Debug]</code>","text":"<p>Configuration for debugging details</p>"},{"location":"Correction%20Algorithm/","title":"Correction Algorithm","text":"<p>After the digitization of the images and the composition to a number a checking and correction algorithm is applied. This is explained here.</p> <p>There are several reasons, that a check might be necessary:</p> <ol> <li>In case of digits there is the output of \"N\" (=NaN = Not-a-Number) in case the digit cannot be detected correctly. This happens for example if the image shows a digit between to states</li> <li>The replacement of the \"N\" with a previous value could be not sufficient, due to the fact, that it might have changed.</li> <li>There is a misreading of one one of the numbers. This can always happen in case of neural network processing.</li> </ol>"},{"location":"Correction%20Algorithm/#terms-and-definitions","title":"Terms and definitions","text":""},{"location":"Correction%20Algorithm/#prevalue","title":"PreValue","text":"<p>The last correct read value. PreValue is here a bit missleading, because normally it is the same as the last value. In the next round of reading it will be used to check nagtive rates, high rates (MaxRateValue / MaxRateType) and CCheckDigitIncreaseConsistency (dig-class11 only). Either from a previous correctly identified value or manual setting by the user. The last correct read value. PreValue is here a bit missleading, because normally it is the same as the last value. In the next round of reading it will be used to check nagtive rates, high rates (MaxRateValue / MaxRateType) and CCheckDigitIncreaseConsistency (dig-class11 only). Either from a previous correctly identified value or manual setting by the user.</p>"},{"location":"Correction%20Algorithm/#digits","title":"Digits","text":"<p>Value that are digitized from a digital number. There are 11 allowed values for this: </p> <ol> <li>Digits: 0, 1, 2, ... 9</li> <li>N = Not-a-Number - representing a not unique state between two numbers</li> </ol>"},{"location":"Correction%20Algorithm/#analogs","title":"Analogs","text":"<p>This are value derived from a pointer like meter. This never has the state \"N\".</p>"},{"location":"Correction%20Algorithm/#checkdigitincreaseconsistency","title":"CheckDigitIncreaseConsistency","text":"<p>If this is enabled an \"intelligent\" algorithm is used to derive from zero-crossing of discrete digit positions, if the number should have been increased. This is relevant because in some of the digit meters, the increase of a digit to the next number can be seen, before the sub-digit has gone through zero.</p> <p>For example: 16.6 --&gt; 16.7 --&gt; 1N.8 --&gt; 17.9 corrected to 16.9 --&gt; 17.0 --&gt; 17.1 </p> <p>As you can see, the 17.9 is a false reading as the 7 is assumed to be already readable, although the sub-digit has not crossed the zero. In this case the CheckDigitIncreaseConsistency algorithm will correct this to 16.9</p> <p>A detailed description of the algorithm can be found below (not yet ready!)</p>"},{"location":"Correction%20Algorithm/#allownegativerates","title":"<code>AllowNegativeRates</code>","text":""},{"location":"Correction%20Algorithm/#allownegativerates_1","title":"<code>AllowNegativeRates</code>","text":"<p>Most of the meters only have increasing numbers and do not count backwards. Therefore a negative rate (= negative change compared to the PreValue) is surely a false value. This can be checked an flagged as false reading</p> <p>The <code>AllowNegativeRates</code> property ensures that the result does not become negative in the event of incorrect readings. This can happen, for example, if the alignment of the image did not work properly. But also the neural networks sometimes flip between two states for similar images.</p> <p>If <code>AllowNegativeRates = true</code>, the result is discarded if it is smaller than the pre-value of the last readout and the output shows an error \"Negative rate..\"</p> <p>If the <code>ExtendedResolution</code> setting is true, there is an exception where the value does not become smaller, but no error is output. This only applies if the value +/- 0.2 of the last digit is inaccurate.</p>"},{"location":"Correction%20Algorithm/#decimalshift","title":"<code>DecimalShift</code>","text":"<p>The <code>DecimalShift</code> setting puts the decimal point in the right place. It acts like a shift. Negative values shift the decimal point to the left. Positive values move the decimal point to the right, filling with zero.</p>"},{"location":"Correction%20Algorithm/#analogdigitaltransitionstart","title":"<code>AnalogDigitalTransitionStart</code>","text":"<p>For detailed description see Analog-digital-transition.</p>"},{"location":"Correction%20Algorithm/#maxratevalue-and-maxratetype","title":"<code>MaxRateValue</code> and <code>MaxRateType</code>","text":"<p>The <code>AllowNegativeRates</code> property ensures that the result does not become negative in the event of incorrect readings. This can happen, for example, if the alignment of the image did not work properly. But also the neural networks sometimes flip between two states for similar images.</p> <p>If <code>AllowNegativeRates = true</code>, the result is discarded if it is smaller than the pre-value of the last readout and the output shows an error \"Negative rate..\"</p> <p>If the <code>ExtendedResolution</code> setting is true, there is an exception where the value does not become smaller, but no error is output. This only applies if the value +/- 0.2 of the last digit is inaccurate.</p>"},{"location":"Correction%20Algorithm/#decimalshift_1","title":"<code>DecimalShift</code>","text":"<p>The <code>DecimalShift</code> setting puts the decimal point in the right place. It acts like a shift. Negative values shift the decimal point to the left. Positive values move the decimal point to the right, filling with zero.</p>"},{"location":"Correction%20Algorithm/#analogdigitaltransitionstart_1","title":"<code>AnalogDigitalTransitionStart</code>","text":"<p>For detailed description see Analog-digital-transition.</p>"},{"location":"Correction%20Algorithm/#maxratevalue-and-maxratetype_1","title":"<code>MaxRateValue</code> and <code>MaxRateType</code>","text":"<p>Here the maximum change from one to the next reading can be limited. If a false reading of the neural network results in a change larger than this, the reading is flagged as false. There a two types of comparisons possible</p> <p>1) AbsolutChange: Here the difference between the PreValue and the current reading is compared directly, independent how much time has passed since the last reading. 2) RelativeRate:  in this case a change rate in the unit of change/minute is calculated, taking the time between the last and the current reading into account. Be careful, that with increasing time, the absolute allowed change increases.    Example: relative rate of 0.05 m\u00b3/minute --&gt; after 20 minutes a maximum change of 20 minutes * 0.05 m\u00b3/minute = 1 m\u00b3 is possible. That means that a false reading of 1 m\u00b3 cannot be detected false after about 20 minutes in this case    Assume, that there might be no change in the meter for hours (e.g. during the night) a much bigger change could also be accepted. </p>"},{"location":"Correction%20Algorithm/#extendedresolution","title":"<code>ExtendedResolution</code>","text":"<p>Newer models such as dig-cont and dig-class100 have a high resolution of the values and can thus represent another digit by using the value of the last digit or pointer (ex. 7.8 in the last digit). </p> <p>If the value is set to true, the result of the last digit is used completely. </p> <p>When using dig-class11 models, the setting is ignored.</p>"},{"location":"Correction%20Algorithm/#ignoreleadingnan","title":"<code>IgnoreLeadingNaN</code>","text":"<p>The parameter is only be used, if a dig-class11 model is selected. <code>\u00ccgnoreLeadingNaN</code> removes in the CheckDigitIncreaseConsistency process the leading <code>N</code> values.</p>"},{"location":"Correction%20Algorithm/#extendedresolution_1","title":"<code>ExtendedResolution</code>","text":"<p>Newer models such as dig-cont and dig-class100 have a high resolution of the values and can thus represent another digit by using the value of the last digit or pointer (ex. 7.8 in the last digit). </p> <p>If the value is set to true, the result of the last digit is used completely. </p> <p>When using dig-class11 models, the setting is ignored.</p> <p>Due to inaccuracies of the neural networks, it sometimes happens that the results jump back and forth between two decimal places. Therefore, when using `\u00c0llowNegatives``= false, no error is output if the value is only off by 0.2. Nevertheless, the value then remains at the higher determined value.</p>"},{"location":"Correction%20Algorithm/#ignoreleadingnan_1","title":"<code>IgnoreLeadingNaN</code>","text":"<p>The parameter is only be used, if a dig-class11 model is selected. <code>\u00ccgnoreLeadingNaN</code> removes in the CheckDigitIncreaseConsistency process the leading <code>N</code> values.</p>"},{"location":"Correction%20Algorithm/#flow-chart","title":"Flow Chart","text":""},{"location":"Correction%20Algorithm/#checkdigitincreaseconsistency-algorithm","title":"CheckDigitIncreaseConsistency Algorithm","text":"<p>The check digit increase consistency algorithm is functional for the digits only. Due to the fact, that the rotation might be a little bit earlier or later compared to the zero crossing of the digit before, errors during the reading before and after a zero crossing can be wrong. Therefore a simple algorithm can be applied, checking the consistency of zero crossing and changes in the following digit. This is applied to one after the other digit, starting with the lowest priority digits.</p> <p></p>"},{"location":"Demo-Mode/","title":"Demo Mode","text":"<p>For Demo and Testing Purpose, the device can use pre-recorded images.</p> <p>You need to enable it in the configuration (<code>TakeImage &gt; Demo</code>) and also provide the needed files on the SD card.</p> <p>For each round one image gets used, starting with the first image for the first round.</p> <p>For the reference image and the alignment also the first image gets used.</p> <p>Once the last image got reached, it starts again with the first one.</p>"},{"location":"Demo-Mode/#sd-card-structure","title":"SD Card Structure","text":"<pre><code>demo/\n\u251c\u2500\u2500 520.8983.jpg\n\u251c\u2500\u2500 520.9086.jpg\n\u251c\u2500\u2500 520.9351.jpg\n\u251c\u2500\u2500 ...\n\u2514\u2500\u2500 files.txt\n</code></pre> <ul> <li>The jpg files can have any name</li> <li>The jpg files must be smaller than 30'000 bytes</li> <li>The <code>files.txt</code> must contains a list of those files, eg:<pre><code>520.8983.jpg\n520.9086.jpg\n520.9351.jpg\n</code></pre> </li> </ul>"},{"location":"Demo-Mode/#recording","title":"Recording","text":"<p>To record real images of a meter, you have to periodically fetch <code>http://&lt;IP&gt;/img_tmp/raw.jpg</code>.</p> <p>To automate this, you can use the following shell script (Linux only):</p> <pre><code>#!/bin/bash\n\nwhile [[ true ]]; do\n    echo \"fetching value...\"\n    wget -q http://192.168.1.151/value -O value.txt\n\n    value=`cat value.txt`\n    echo \"Value: $value\"\n\n    diff=`diff value.txt value_previous.txt`\n    changed=$?\n    #echo \"Diff: $diff\"\n\n    if [[ $changed -ne 0 ]]; then\n        echo \"Value changed:\"\n        echo $diff\n        echo \"fetching image...\"\n        wget -q http://192.168.1.151/img_tmp/raw.jpg -O $value.jpg\n    else\n        echo \"Value did not change, skipping image fetching!\"\n    fi\n\n    cp value.txt value_previous.txt\n\n    echo \"waiting 60s...\"\n    sleep 60\ndone\n</code></pre>"},{"location":"Demo-Mode/#installation","title":"Installation","text":"<p>Just install the zip file using the OTA Update functionality.</p>"},{"location":"Demo-Mode/#how-does-it-work","title":"How does it work","text":"<p>The Demo Mode tries to interfere as less as possible with the normal behavior. Whenever a Cam framebuffer gets taken (<code>esp_camera_fb_get()</code>), it replaces the framebuffer with the image from the SD card.</p>"},{"location":"Demo-Mode/#example-data-of-a-water-meter","title":"Example Data of a Water Meter","text":"<p>You can use the following demo images if you want:</p> <p></p> <p>It covers a meter range from <code>530.00688</code> to <code>531.85882</code>.</p>"},{"location":"Demo-Mode/#animation","title":"Animation","text":"<p>Animation of the watermeter (77 MB!)</p>"},{"location":"Demo-Mode/#selection-of-84-images","title":"Selection of 84 images","text":"<p>Demo_Images_Watermeter_530.00688-532.08243_84_images.zip</p>"},{"location":"Demo-Mode/#selection-of-42-images","title":"Selection of 42 images","text":"<p>Demo_Images_Watermeter_530.00688-532.08243_42_images.zip</p>"},{"location":"Demo-Mode/#all-images-843-images","title":"All images (843 images)","text":"<p>Demo_Images_Watermeter_530.00688-532.08243_843_images.zip</p>"},{"location":"Error-Codes/","title":"Reduced webinterface (error indication and tracing)","text":"<p>Whenever an error occurs during boot process which avoids loading of regular processing and regular webinterface, a reduced webinterface gets loaded to have at least some visual feedback and the possibilitiy to figure out the root cause by browsing the logfiles or trigger another OTA update.</p> <p>The error code(s) get printed with specific error codes. This page lists the possible error codes, their meaning and possible solutions.</p> <p>Note: Here the error codes are defined in source code: error codes.</p>"},{"location":"Error-Codes/#critical-errors","title":"Critical Errors","text":"<p>Those Errors make the normal operation of the device impossible. Most likely they are caused by a hardware issue!</p>"},{"location":"Error-Codes/#0x00000001-psram-bad","title":"<code>0x00000001</code> PSRAM bad","text":"<p>Your device most likely has no PSRAM at all or it is too small (needs to have at least 4 MBytes)! See Hardware Compatibility.</p> <p>Usually the log shows something like this:</p> <pre><code>psram: PSRAM ID read error: 0xffffffff\ncpu_start: Failed to init external RAM!\n</code></pre>"},{"location":"Error-Codes/#0x00000002-heap-too-small","title":"<code>0x00000002</code> Heap too small","text":"<p>The firmware failed to allocate enough memory. This most likely is a consequential error of a bad PSRAM!</p>"},{"location":"Error-Codes/#0x00000004-cam-bad","title":"<code>0x00000004</code> Cam bad","text":"<p>The attached camera can not be initialized. This usually is because on of the following reasons:</p> <ul> <li>The camera is not supported, see Hardware Compatibility</li> <li>The camera is not attached properly -&gt; Try to remove and attach it again. Make sure you move the black part enough into the socket!</li> <li>The camera or the camera cable is damaged</li> </ul>"},{"location":"Error-Codes/#0x00000008-sd-card-basic-check-failed","title":"<code>0x00000008</code> SD card basic check failed","text":"<p>One or more basic SD card checks failed.</p> <p>The following checks are performed during boot sequence:</p> <ul> <li>Write a file (sdcard/sdcheck.txt) to SD card with some generic text</li> <li>Read the written file back</li> <li>CRC verification</li> <li>Delete the file</li> </ul> <p>Detailed error indication (write, rerad or delete error) can be derived from blinking code of red board status LED. Please refer to StatusLED-BlinkCodes</p> <p>Recommendation: Reformat SD card and check again or try another SD card</p>"},{"location":"Error-Codes/#0x00000010-sd-folder-or-file-presence-check-failed","title":"<code>0x00000010</code> SD folder or file presence check failed","text":"<p>One or more mandatory folders and/or files are missing on SD card. To have early indication that SD card is potentially ready for operation, some folder and files, which are mandatory are presence checked. This is not a 100% check and a successful test does not mean everthing is OK.</p> <p>The following folders / files get checked during boot sequence:</p> <ul> <li>/sdcard/config</li> <li>/sdcard/html</li> <li>/sdcard/demo --&gt; created automatically in firmware</li> <li>/sdcard/firmware --&gt; created automatically in firmware</li> <li>/sdcard/img_tmp --&gt; created automatically in firmware</li> <li>/sdcard/log --&gt; created automatically in firmware</li> <li>/sdcard/wlan.ini</li> <li>/sdcard/config/config.ini</li> <li>/sdcard/html/index.html</li> <li>/sdcard/html/ota_page.html</li> <li>/sdcard/html/log.html</li> <li>/sdcard/html/common.js</li> <li>/sdcard/html/version.txt</li> </ul> <p>Note: This list might be outdated, see the source code for the latest implementation: SDCardCheckRW()</p> <p>Recommendation: Check logs and / or redo a Over-The-Air Update (OTA Update) to ensure proper SD card structure</p>"},{"location":"Error-Codes/#non-critical-errors","title":"Non-Critical Errors","text":"<p>Those Errors can be caused by an error during initialization. It is possible that the error has no impact at all or that a reboot solves it.</p>"},{"location":"Error-Codes/#0x00000100-cam-framebuffer-bad","title":"<code>0x00000100</code> Cam Framebuffer bad","text":"<p>The firmware was unable to initialize the Camera Framebuffer. The firmware will continue to work, but other consequential error might arise. A reboot of the device might help.</p> <p>This might also be caused by a corrupred SD-Card, see CAM is not working anymore\" on init #2390</p>"},{"location":"Error-Codes/#0x00000200-ntp-failed","title":"<code>0x00000200</code> NTP failed","text":"<p>The firmware failed to get the world time from an NTP server. The firmware will continue to work, but has a wrong time.</p>"},{"location":"Error-Debugging/","title":"Often observed issues","text":""},{"location":"Error-Debugging/#hardware-failure","title":"Hardware failure","text":"<ul> <li>Camera not working --&gt; check the interface, test another module</li> <li>Low cost module with no or only 2MB memory instead of 4MB --&gt; test another module</li> <li>SD card issues --&gt; test another SD card</li> <li>Wifi reception bad / unstable --&gt; bad antenna, test another module or use external antenna</li> </ul> <p>More information in terms of hardware, component and basic configuration issues can be found here: Reboot reasons</p>"},{"location":"Error-Debugging/#roi-misaligned","title":"ROI misaligned","text":"<p>This typically happens if you have suboptimal \"Alignment Marks\". A very simple and working solution is to put put higly contrasted stickers on your meter and put \"Alignment Marks\" on it (see picture below)</p> <p></p> <p>If after those adjustment you still have some issues, you can try to adjust your alignment settings in expert mode: </p>"},{"location":"Error-Debugging/#my-analog-meter-are-recognized-as-digital-counter-or-vice-versa","title":"My Analog Meter are recognized as Digital Counter or vice versa","text":"<ol> <li>First, check that your ROI are correctly defined (yey!)</li> <li>Second, verify that the name of your ROI analog and digital ROIs are different </li> </ol>"},{"location":"Error-Debugging/#recognition-is-working-well-but-number-arent-sorted-correctly","title":"Recognition is working well, but number aren't sorted correctly","text":"<p>You have to sort your ROI correctly (Bigger to smaller). Select your ROI and click either \"move next\" or \"move previous\". Repeat until your ROI are correctly sorted</p> <p></p>"},{"location":"External-LED/","title":"External LED","text":"<p>The internal flash LED is very close to the camera axis. This results in reflection, especially in case of flat glass surfaces such as for power meters. To circumvent this problem, it is now possible to control external LEDs, which than can be places somewhere else in the setup. As not simples LEDs are used, but RGB LEDs with a digital interface like WS2812 not only the position, but also the color and intensity of the illumination can now be adjusted. The following image shows a direct comparison of the \"old\" internal flash LED and two off axis LEDs.</p> <p></p> <p>There is also a new meter adapter available. This has two features: designed for small clearings in front of the meter and prepared for WS2812 LEDs.</p> <p></p>"},{"location":"External-LED/#1-hardware-installation-of-the-led-stripe","title":"1. Hardware installation of the LED stripe","text":"<p>The control line of the LED stripe is connected with a 470 Ohm resistor to the GPIO12.  For power supply stabilization a capacitor between 5V and ground is recommended. Here a 470\u00b5F polymer capacitor is used. As a power supply a 5V from the ESP32 is used like in the following wiring.</p> <p> </p>"},{"location":"External-LED/#2-software-configuration","title":"2. Software configuration","text":"<p>The handling of the WS2812 LED controller needs some other libraries, therefore it is controlled within a dedicated section called <code>GPIO Settings</code>. The external LED stripe is connected to GPIO12. After activating the \"GPIO Settings\" section, the internal flash is per default disabled. In order to activate the external LED, you need to activate <code>GPIO 12 state</code> and select <code>\"extern flash light ws281x ...\"</code>. </p> <p> </p> Parameter Meaning LED-Type There are several types of controller implemented: WS2812(B), WS2813, SK6812 Numbers of LED Number of LEDs on the LED stripe LED Color The color and intensity can be controlled directly by a red/green/blue value, each within the range from 0 (off) to 255 (full) <p>Enabling the GPIO settings automatically disables the flash LED. Therefore you can enable it here manually by checking GPIO4 and choose <code>\"build-in led flash light\"</code>. It is not recommended to use both illumination parallel. </p>"},{"location":"FAQs/","title":"Frequently Asked Questions","text":""},{"location":"FAQs/#my-device-reboots-frequently-what-can-i-do","title":"My device reboots frequently. What can I do?","text":"<p>There are several reasons for frequent reboots:</p> <ul> <li>Frequent HTML requests</li> <li>Wrong configuration, missing configuration files</li> <li>Unstable hardware - see Hardware Compatibility.</li> </ul> <p>There is a dedicated page about this: Frequent Reboots.</p>"},{"location":"FAQs/#bad-webui-responsiveness-what-can-i-do","title":"Bad WebUI responsiveness. What can I do?","text":"<p>This is usually due to hardware or WLAN issues. There are already many entries in discussion section, some of which have good tipps.</p> <p>Possible checks / ideas:</p> <ul> <li>ESP32CAM hardware antenna design is very poor in connection with camera frequency.</li> <li>Simple test: When the device is in operation, putting your thumb on the camera connector and the directly adjacent components should make the device respond more quickly.</li> <li>Possible optimization: Here, an attempt was made to dampen the frequency influences somewhat by shielding.  Shielding Example</li> <li>WLAN channel: Preferably use channel 1, 6 or 11</li> <li>Performance can vary depending on the AP manufacturer. If necessary, check with a mobile hotspot or other device to exclude AP influence</li> <li>Try with an external antenna</li> <li>Avoid VLAN, currently not fully supported</li> <li>Temporarily deactivate virus scanner / firewall on the end device for testing purpose</li> <li>Use sufficiently dimensioned power supply</li> <li>Use a branded SD card (formatted with Windows, MAC often causes problems)</li> </ul> <p>Check discussion section for possible further tipps.</p>"},{"location":"FAQs/#how-accurate-are-the-detections","title":"How accurate are the detections?","text":"<p>It is hard to give a specific accuracy number. It depends on many factors, e.g.</p> <ul> <li>How in-focus is your camera?</li> <li>How sturdy is the camera mount? Does it slightly move over extended periods of time?</li> <li>What type of meter are you reading? Is the meter already in the training data set?</li> <li>Are you trying to read digits, an analog dial, or both?</li> <li>etc.</li> </ul> <p>Anecdotally, the authors of this page have great success with the meter. While the AI algorithm itself is not perfect and sometimes returns <code>NaN</code> or incorrect values, other post-processing / prevalue / sanity checks help ensure such invalid values are filtered out. With the correct settings, one author has been running this device for 1 month without any incorrect values reported. </p> <p>See the FAQs below for more details and configuration hints.</p>"},{"location":"FAQs/#my-numbers-are-not-correctly-detected-what-can-i-do","title":"My numbers are not correctly detected. What can I do?","text":"<ul> <li>There is a dedicated page about the correct setting ROI Configuration.</li> <li>This page also includes the instructions for gathering new images for the training.</li> </ul>"},{"location":"FAQs/#how-can-i-ensure-invalid-numbers-are-never-reported","title":"How can I ensure invalid numbers are never reported?","text":"<p>As mentioned above, the AI algorithm is not perfect. Sometimes it may read an incorrect value.</p> <p>We can tune the software to almost never report an incorrect value. There is a tradeoff though: the software may report stale values - i.e. it will drop incorrect values for a potentially long period of time, resulting in the meter reading being outdated by hours. If never receiving an incorrect value is important to you, consider tolerating this tradeoff.</p> <p>You can change the following settings to reduce incorrect readings (but potentially increase staleness of data):</p> <ul> <li>Set a prevalue via the UI, then change <code>PostProcessing</code> configuration option <code>PreValueAgeStartup</code> to a much larger number (e.g. <code>43200</code> = 30 days).</li> <li>Change <code>PostProcessing</code> configuration option <code>MaxRateType</code> to be time based instead of absolute. Set <code>MaxRateValue</code> to something realistic (e.g. <code>5</code> gal/min). You can often find the max flow rate your meter supports directly on the cover.</li> <li>Reduce <code>AutoTimer</code> configuration option <code>Interval</code> to the lowest it can be (e.g. <code>3</code> min). The more often you take readings, the less likely for data staleness to occur.</li> </ul>"},{"location":"FAQs/#even-after-i-have-setup-everything-perfect-there-is-a-false-reading-especially-around-the-zero-crossing-roll-over-to-next-number","title":"Even after I have setup everything perfect there is a false reading - especially around the zero crossing (roll over to next number)","text":"<ul> <li>The roll over behavior is different for the different meters. E.g.:</li> <li>Rolling over start with different previous position (e.g. at 7, 8 or 9)</li> <li> <p>The neutral position (no rolling) is not perfectly at zero, but rather at something like 7.9 or 8.1, even if it should be exactly 8</p> </li> <li> <p>The \"PostProcessingAlgo\" is trying to judge out of the individual readings, what number it should be. </p> </li> <li> <p>For example if the previous number is a \"1\", but the next number seems to be a \"8.9\", most probably there was a \"zero crossing\" and the number is a \"9\" and not still an \"8\"</p> </li> <li> <p>Currently the setting of the algorithm is set to fit most of the meters and cases. But the parameters do not fit perfectly for all situations. Therefore there might be intermediate states, where the reading is false.    This is especially the case, at the positions, where the roll over (zero crossing) is just starting.</p> </li> <li>To prevent a sending of false parameters, there is the possibility to limit the maximum allowed change (MaxRateChange).   Usually after some time and movement of the counters a bit further, the reading is getting back to a stable reading.</li> <li>To handle this, a parametrized setting would be needed. This is rather complicated to implement as subtle changes make a relevant difference. Currently this is not implemented.    So please be a bit patient with your meter :-)</li> </ul>"},{"location":"FAQs/#pre-value","title":"Pre-Value","text":"<p>PreValue is here a bit missleading, because normally it is the same as the last value. In the next round of reading it will be used to check nagtive rates, high rates (MaxRateValue / MaxRateType) and CheckDigitIncreaseConsistency (dig-class11 only). Either from a previous correctly identified value or manual setting by the user.</p> <p>If you use post processes, enable the pre-value. The pre-value must be set at first time. Set it to the current raw value. </p> <p>If the device runs in errors, the pre-value will not be updated, as long as the <code>preValueAgeStartup</code> time between the last valid value (or startup time) and current time is not exceeded. After it the preValue will be set again, if no other error occured. So the device can not run in an endless error, like high rate.</p>"},{"location":"FAQs/#rate-too-high-read","title":"\"Rate too high - Read: ...\"","text":"<p>In configuration you can set the <code>MaxRateValue</code> and <code>MaxRateType</code>. The settings suppress improbably high values that can come from false readings. To do this, the value must be set correctly depending on your meter.</p> <p>Before doing this, you should be clear about the type of rating you want to use.</p> <ul> <li><code>Absolute change</code> is the interval between two readings - no matter how often the readings happen. </li> <li><code>RateCange</code> is the change per minute. This is calculated from the time difference between the last and the current reading. </li> </ul> <p>If there is an interval of 5 minutes between readings and a MaxRateValue of 1, an error \"Rate too high - Read: ...\" if </p> <ul> <li>Absolute change: the difference is <code>&gt; 1</code></li> <li>RateChange: the difference is <code>&gt; 1 / 5</code></li> </ul>"},{"location":"FAQs/#train-on-my-own-images","title":"Train on my own images","text":"<p>Look at Learn models with your own images and Cookbook running the jupyter notebook with my own data.</p>"},{"location":"Frequent-Reboots/","title":"Basic hardware / configuration issues","text":"<p>If the device is behaving eratically or not running as expected you can use the following tools trying to identify the root cause:</p> <ol> <li>Internal logging (<code>config.ini</code>)    --&gt; Set to DEBUG log level</li> <li>Reduced web interface (only error indication visualization, Error codes on reduced webinterface)</li> <li>Red board LED: Status LED Blinkcodes</li> <li>Serial log of the UART interface (USB access needed, only local, same as for flashing the firmware)</li> </ol> <p>There are in principle two reboots types:</p> <ol> <li>Sporadic random reboots (always different timing and situation)</li> <li>Repeating boot loops (reoccuring, always stop working after same precondition)</li> </ol>"},{"location":"Frequent-Reboots/#sporadic-random-reboots","title":"Sporadic random reboots","text":"<p>Sporadic random reboots could have the following reasons:</p> <ul> <li>In general: Unstable system due to software issues (e.g. overload during HTML access, ...)   --&gt; Trying the figure out what's the root cause to fix the issue</li> <li>Bad power supply   --&gt; The power supply need to stable to ensure proper operation of the device. If it's not stable the device tents to sporadic reboots (brownout detection)</li> </ul> <p>In general: There are several mechanisms in the firmware (like saving previous values), to have a \"smooth\" reboot without too many notable disturbance.</p>"},{"location":"Frequent-Reboots/#system-instabilities","title":"System instabilities","text":"<p>If your system is sometimes running smoothly over several runs and sometimes reboots obviously randomly, you have an partially unstable device. </p> <p>You can check this in the standard log file on the SD card:</p> <pre><code>2021-12-26T06:34:09: task_autodoFlow - round done\n2021-12-26T06:34:09: CPU Temperature: 56.1\n2021-12-26T06:38:00: task_autodoFlow - next round - Round #23\n</code></pre> <p>Here you see, that the round #23 is starting, so obviously there were no reboots in the last 22 rounds. There is hardware (ESP32CAM), where only 2-3 stable rounds are possible and others, where way more than 100 rounds without any reboots is possible. There is noting you can do about it, beside testing different hardware.</p>"},{"location":"Frequent-Reboots/#overload-during-html-access","title":"Overload during HTML access","text":"<p>If you frequently access the web server over HTML requests, the firmware tends to reboot. This especially happens during the first run and when the ESP32 is busy with the digitization flow. </p> <p>The reason for this are running out of memory during a flow, minor memory leakage in combination with missing error handling.</p> <p>There is noting you can do about this kind of reboot, beside two thing:</p> <ol> <li>Support the firmware development with improved and tested part of code</li> <li>Be patient :-)</li> </ol>"},{"location":"Frequent-Reboots/#bad-or-insufficient-power-supply","title":"Bad or insufficient power supply","text":"<p>A good and stabilized power supply is essential to have error free operation. The device is quite picky in terms of proper power supply. Especially the wifi module have some load spikes which the power supply needs to cover. If the power is not stable enough, the brwonout mechanism is protecting against strange behaviour and force a reboot whenever the voltage drops below a specific level. You can see this in random reboots which indication is logfile: --&gt; Reset reason: Brownout</p>"},{"location":"Frequent-Reboots/#repeating-boot-loops","title":"Repeating boot loops","text":"<p>Repeating boot loops at the same situation during the flow has a systematic problem either in the hardware or the configuration. It usually happens during initialization state or processing the first round as there all needed parts of the firmware have been loaded for the first time.</p> <p>To identify the root cause the logfiles, the reduced web interface, the red board LED or the serial log of the UART interface (no remote access, USB access needed) is helpful. </p> <p>Possible issues:</p> <ul> <li>SD card related issues</li> <li>RAM related issues</li> <li>Configuration related issues</li> </ul>"},{"location":"Frequent-Reboots/#sd-card-related-issues","title":"SD card related issues","text":"<p>The ESP32CAM is a little bit \"picky\" with the supported SD cards. Due to the limited availability of GPIOs the SD card can only be accessed via 1-wire mode. Therefore not all SD cards are supported. The following error cases can occur:</p>"},{"location":"Frequent-Reboots/#sd-card-wrong-filesystem-only-fat32-is-supported","title":"SD card: Wrong filesystem (only FAT32 is supported)","text":"<p>If this SD card error is detected only the following indications are available. No web interface will be accessible.</p> <ul> <li>Red board LED is blinking. The blinking codes are described here: Status LED Blinkcodes</li> <li>Error messages on serial log (UART interface)</li> </ul>"},{"location":"Frequent-Reboots/#sd-card-not-detected-not-supported","title":"SD card not detected / not supported","text":"<p>If this SD card error is detected the following indication are available. No web interface will be accessible.</p> <ul> <li>Red board LED is blinking. The blinking codes are described here: Status LED Blinkcodes</li> <li>Error messages on serial log (UART interface)</li> </ul>"},{"location":"Frequent-Reboots/#sd-card-detected-but-files-are-not-readable-writeable","title":"SD card detected but files are not readable / writeable","text":"<p>The SD card is detected, but the files cannot be read or written. A basic SD card check for SD reading / writing is performed on every boot. This not 100% guarantee that SD card is working but it's at least a indication.</p> <p>If this SD card error is detected the following indications are available:</p> <ul> <li>The reduced web interface will be loaded to have visual feedback of error situation. Regualar processing is disabled, though. Within this reduced web interface logs can be viewed to have further indication what's the root cause. Error code desciption can be found here: Error codes on reduced webinterface</li> <li>Error messages in logfile</li> <li>Red board LED is blinking. The blinking codes are described here: Status LED Blinkcodes</li> <li>Error messages on serial log (UART interface)</li> </ul>"},{"location":"Frequent-Reboots/#ram-related-issues","title":"RAM related issues","text":"<p>In order to run the firmware, 4 MB of external RAM (PSRAM) are mandatory. Usually, the ESP32CAM is equipped with 8MB (64Mbit) PSRAM chip, whereof only 4MB can be used effectively (direct addressable). Unfortunately, there is hardware around, where no PSRAM or only 2MB of PSRAM is present - even if you have bought a device where a 8MB PSRAM was promoted. These modules are not suiable for this firmware because the external RAM is needed to handle the CNN files and camera images. There is nothing to do, than to buy a new ESP32CAM with really 64MBit of PSRAM. </p>"},{"location":"Frequent-Reboots/#too-less-external-ram-psram","title":"Too less external RAM (PSRAM)","text":"<p>During the boot process the available RAM is going to be checked.</p> <p>If there is too less RAM (PSRAM or total HEAP &lt; 4MB) detected, the follwoing indications are available:</p> <ul> <li>The reduced web interface will be loaded to have visual feedback of error situation. Regualar processing is disabled, though. Within this reduced web interface logs can be viewed to have further indication what's the root cause. Error code desciption can be found here: Error codes on reduced webinterface</li> <li>Error messages in logfile</li> <li>Red board LED is blinking. The blinking codes are described here: Status LED Blinkcodes</li> <li>Error messages on serial log (UART interface)</li> </ul>"},{"location":"Frequent-Reboots/#configuration-related-issues","title":"Configuration related issues","text":""},{"location":"Frequent-Reboots/#folders-and-files-missing","title":"Folders and files missing","text":"<p>Most of the relevant folders and files are checked during boot. The complete list can be found here: Error codes on reduced webinterface</p> <p>If a relevant folder or file is missing the following indications are available:</p> <ul> <li>The reduced web interface will be loaded to have visual feedback of error situation. Regualar processing is disabled, though. Within this reduced web interface logs can be viewed to have further indication what's the root cause. Error code desciption can be found here: Error codes on reduced webinterface</li> <li>Error messages in logfile</li> <li>Red board LED is blinking. The blinking codes are described here: Status LED Blinkcodes</li> <li>Error messages on serial log (UART interface)</li> </ul>"},{"location":"Frequent-Reboots/#cnn-model-file-not-available-corrupt","title":"CNN model file not available / corrupt","text":"<p>Additionally for operation CNN model files on SD card are mandatory, one CNN model file for analog counter and for for digit numbers each.</p> <ul> <li><code>/config/XXXXX.tflite</code> (XXXXX is the file name, that is written in the <code>config.ini</code>)</li> </ul> <p>If the files which are configured in <code>config.ini</code> are not present or corrupt, the process is going to be interrupted (or at worst case a device crash occurs). Please check logs files to have an indicator for the root cause.</p> <p>This a logfile extract (DEBUB log level) where digit CNN model file is not present. The system is initializing the system and trying to load the model files:</p> <pre><code>[0d00h05m11s] 2023-03-27T12:25:14 [TFLITE] CTfLiteClass::LoadModel\n[0d00h05m11s] 2023-03-27T12:25:14 [TFLITE] CTfLiteClass::ReadFileToModel: /sdcard\n[0d00h05m11s] 2023-03-27T12:25:14 [PSRAM] Failed to allocate 0 bytes in PSRAM for 'TFLITE-&gt;modelfile'!\n[0d00h05m11s] 2023-03-27T12:25:14 [TFLITE] CTfLiteClass::ReadFileToModel: Can't allocate enough memory: 0\n[0d00h05m12s] 2023-03-27T12:25:14 [HEAP] CTfLiteClass::ReadFileToModel Heap Total: 2266214 | SPI Free: 2205939 | SPI Large Block: 2162688 | SPI Min Free: 2205423 | Int Free: 60275 | Int Large Block: 55296 | Int Min Free: 46451\n[0d00h05m12s] 2023-03-27T12:25:14 [CNN] Can't load tflite model -&gt; Init aborted!\n[0d00h05m12s] 2023-03-27T12:25:14 [HEAP] getNetworkParameter-LoadModel Heap Total: 2266214 | SPI Free: 2205939 | SPI Large Block: 2162688 | SPI Min Free: 2205423 | Int Free: 60275 | Int Large Block: 55296 | Int Min Free: 46451\n[0d00h05m12s] 2023-03-27T12:25:14 [PSRAM] Freeing memory in PSRAM used for 'TFLITE-&gt;modelfile'...\n[0d00h05m12s] 2023-03-27T12:25:14 [PSRAM] Freeing memory in PSRAM used for 'TFLITE-&gt;tensor_arena'...\n[0d00h05m12s] 2023-03-27T12:25:14 [PSRAM] Allocated 819200 bytes in PSRAM for 'TFLITE-&gt;tensor_arena'\n[0d00h05m12s] 2023-03-27T12:25:14 [TFLITE] CTfLiteClass::LoadModel\n[0d00h05m12s] 2023-03-27T12:25:14 [TFLITE] CTfLiteClass::ReadFileToModel: /sdcard/config/ana-cont_1105_s2_q.tflite\n[0d00h05m12s] 2023-03-27T12:25:15 [PSRAM] Allocated 53328 bytes in PSRAM for 'TFLITE-&gt;modelfile'\n[0d00h05m12s] 2023-03-27T12:25:15 [TFLITE] CTfLiteClass::MakeAllocate\n[0d00h05m12s] 2023-03-27T12:25:15 [PSRAM] Freeing memory in PSRAM used for 'TFLITE-&gt;modelfile'...\n[0d00h05m12s] 2023-03-27T12:25:15 [PSRAM] Freeing memory in PSRAM used for 'TFLITE-&gt;tensor_arena'...\n</code></pre> <ul> <li>Bad config example:</li> <li> <p><code>[0d00h05m11s] 2023-03-27T12:25:14 [TFLITE] CTfLiteClass::ReadFileToModel: /sdcard</code>     --&gt; model file missing: check configuration or file presence </p> </li> <li> <p>Good config example:</p> </li> <li><code>[0d00h05m12s] 2023-03-27T12:25:14 [TFLITE] CTfLiteClass::ReadFileToModel: /sdcard/config/ana-cont_1105_s2_q.tflite</code>     --&gt; model file found: config OK</li> </ul>"},{"location":"Hardware-Compatibility/","title":"Hardware Compatibility","text":""},{"location":"Hardware-Compatibility/#general-remark","title":"General Remark","text":"<p>Although a board looks similar, it can have major differences, e.g.:</p> <ul> <li>Processor</li> <li>Ram (Size! &amp; Type) -&gt; this Project needs at least 4MB RAM!</li> <li>Flashrom</li> <li>Camera Modules</li> <li>Onboard/External Antenna</li> <li>Quality of Components</li> <li>Manufacture Quality of the PCB and soldering</li> <li>Different Components</li> <li>\"Clone\" Components -&gt; ESPxx</li> <li>etc.</li> </ul> <p>This can cause different Power Consumption, Power Requirements, compatibility issues, etc.</p> <p>Most manufacturers and sellers buy what's cheap today on the Asian markets. In the end, it looks like it is sometimes a trial and error approach which ESP32-CAM Module works reliably.</p> <p>Below you find some remarks and experiences from the community:</p>"},{"location":"Hardware-Compatibility/#esp32-core-itself","title":"ESP32 core itself","text":"Chip Version Image Status ESP32-D0WDQ6 (revision 1) \u2714\ufe0f"},{"location":"Hardware-Compatibility/#psram","title":"PSRAM","text":"<p>There seems to be a lot of \"fake\" chips, or maybe wrongly configured ESP32 Boards.</p> <p>For AP MEMORY, all \"real\" APS6404*3SQR chips should work.</p> <p>For ESP PSRAM, all \"real\" PSRAM64* should work.</p> <p>64Mbit density = 8Mbyte PSRAM</p> <p>This Table is just a snapshot of chips which worked</p> Labeling on PSRAM module Image Status IPUS / IPS640LS0 / 1815XBGN \u2714\ufe0f AP MEMORY / 6404L-3SOR / 1040H / 110089G \u2714\ufe0f AP MEMORY / 6404L-3SQR / 12205 / 150047G \u2714\ufe0f 8MB AP MEMORY / 6404L-3SQR / 12208 / 150047G \u2714\ufe0f 8MB AP MEMORY / 6404L-350R / 1120A / 130027G \u274c PSRAM not accessible AP MEMORY / 6404L-35QR / 11208 / 130025G \u274c PSRAM not accessible AP MEMORY / 6404L-3SQR / 13100 / 180026G \u274c PSRAM not accessible AP MEMORY / 6404L-3SQR / 11207 / 130024G \u274c PSRAM not accessible AP MEMORY / 6404L-3SQR / 1120A / 130027G \u2714\ufe0f 8MB AP MEMORY / 6404L-3SQR / 1120B / 130028G \u2714\ufe0f 8MB AP MEMORY / 6404L-3SQR / 1120D / 130030G \u2714\ufe0f 8MB AP MEMORY / 1604M-3SQR / 0280A / 070036G \u274c 2MB only! ESP PSRAM64H 462021 / 1B00286 \u2714\ufe0f ESP PSRAM64H 412021 / 1A0039G \u2714\ufe0f 8MB ESP PSRAM64H 402021 / 1A0017N \u274c PSRAM not accessible ESP PSRAM16M 302020 \u274c 2MB only! ESP PSRAM16H 202020 / 050022G \u274c 2MB only!"},{"location":"Hardware-Compatibility/#ov2640-camera","title":"OV2640 - Camera","text":"<p>The experience with the camera only is based on single modules. It is well possible, that this module had a damage overall and other modules of the same type will work. Give it a try and report to me!</p> Labeling on Flex-Connector Image Status TY-OV2 / 640-V2.0 \u2714\ufe0f DCX-OV2 / 640-V2 \u2714\ufe0f DC-26 / 40-V3 \u2714\ufe0f 3x \u274c 1x"},{"location":"Hardware-Compatibility/#esp32-modules","title":"ESP32 Modules","text":"Module Image Status ESP32CAM / Different versions on the market!Especially the PSRAM is sometimes labeled wrong(Label: 4MB, Real: only 2 MB --&gt; will not work!) \u2714\ufe0fwith &gt;=4 MB PSRAM! ESP32-S3-EYENo Flash LED, pins different used (e.g. LCD display) NOT OKAY"},{"location":"Hardware-Compatibility/#sd-cards","title":"SD Cards","text":"<p>Due to the limited free available GPIOs (due to all the extensions needed like: camera, SD card, LED-flash, ...) the SD card is connected in 1-wire mode. There are some cards, that are compatible with the esp32cam module for unknown reasons. It is observed, that smaller cards (up to 4 GB) tend to be more stable and larger cards have more problems. But quite some exceptions in the forums (4 GB cards not working, 16 GB cards working like a charm).</p>"},{"location":"Hardware-Compatibility/#devices-known-to-work","title":"Devices known to work","text":""},{"location":"Hardware-Compatibility/#modules-old-list-not-up-to-date-anymore","title":"Modules (Old list, not up-to-date anymore):","text":"<p>See https://github.com/jomjol/AI-on-the-edge-device/discussions/1732 for a more recent list.</p> <ul> <li> <p>https://arduino-projekte.info/produkt/esp32-cam-v2-integriertem-ch340-mit-ov2640-kamera-modul/ (see https://github.com/jomjol/AI-on-the-edge-device/discussions/1041)</p> </li> <li> <p>https://www.amazon.de/-/en/gp/product/B0B51CQ13R</p> </li> <li> <p>https://www.reichelt.de/entwicklerboards-esp32-kamera-2mp-25--debo-cam-esp32-p266036.html?PROVID=2788&amp;gclid=CjwKCAiAqaWdBhAvEiwAGAQlttJnV4azXWDYeaFUuNioMICh-jvxKp6Cifmcep9vvtoT2JRCDqBczRoC7Q0QAvD_BwE (27.12.2022)</p> </li> </ul>"},{"location":"Hardware-Compatibility/#sd-card","title":"SD Card","text":"<ul> <li>Sandisk 2GB Micro SD Class 2 Sandisk 2GB AITRIP ESP32 and CAM ESP-32/CAM</li> <li>Amazon US - Aideepen ESP32-CAM W BT Board ESP32-CAM-MB Micro USB to Serial Port CH-340G with OV2640 2MP Camera Module Dual Mode with Amazon US - Cloudisk 5Pack 4GB Micro SD Card 4 GB MicroSD Memory Card Class6</li> </ul>"},{"location":"Hardware-Compatibility/#weak-wifi","title":"Weak Wifi","text":"<p>The ESP32-CAM supports an external antenna. It requires some soldering skills but can improve the connection quality. See https://randomnerdtutorials.com/esp32-cam-connect-external-antenna/</p>"},{"location":"Influx-DB/","title":"Influx DB","text":"<p>The device also supports direct sending of data to an Influx DB.</p> <p>See also Influx Graph in Home Assistant.</p>"},{"location":"Installation/","title":"Installation","text":"<p>The installation requires multiple steps:</p> <ol> <li>Get the right hardware and wire it up</li> <li>Flash the firmware onto the ESP32</li> <li>Write the data to the SD card</li> <li>Start it</li> </ol> <p>For point 2 and 3 we provide multiple ways to do it. Pick the one that looks the easiest for you!</p>"},{"location":"Installation/#1-hardware","title":"1. Hardware","text":""},{"location":"Installation/#esp32-cam","title":"ESP32-CAM","text":"<ul> <li>OV2640 camera module</li> <li>Micro SD card slot </li> <li>4 or 8 MB PSRAM. </li> </ul> <p>It can be easily found on the typical internet stores, searching for ESP32-CAM for less than 10 EUR. How ever since the hardware is cheap and coming from China, you unluckily could pick a malfunctioning device. See Hardware Compatibility for further advice! </p>"},{"location":"Installation/#usb-uart-interface","title":"USB-&gt;UART interface","text":"<p>For first time flashing the firmware a USB -&gt; UART connector is needed. Later firmware upgrades than can be flashed via OTA.</p>"},{"location":"Installation/#power-supply","title":"Power supply","text":"<p>For power supply a 5V source is needed. Most easily this can be done via a USB power supply. The power supply should support minimum 500mA. For buffering current peaks some users reported to use a large electrolytic capacitor like a 2200uF between ground and VCC.</p> <p>Warning</p> <p>In several internet forums there are problems reported, in case the ESP32-CAM is only supplied with 3.3V.</p>"},{"location":"Installation/#housing","title":"Housing","text":"<p>A small 3D-printable example for a very small case can be found in Thingiverse here: https://www.thingiverse.com/thing:4571627</p> <p> </p> <p>Warning</p> <p>The focus of the OV2640 needs to be adjusted, as it is normally set from ~40cm to infinity. In order to get an image that is big enough, it needs to be changed to about 10cm. Therefore the sealing glue on the objective ring needs to be removed with a scalpel or sharp knife. Afterwards the objective can be rotated clockwise until the image is sharp again.</p> <p></p>"},{"location":"Installation/#wiring","title":"Wiring","text":"<p>Beside the 5V power supply, only for the first flashing a connection to the USB-UART connector, including a short cut of GPIO0 to GND for bootloader start.</p> <p>A example for wiring can be found here:</p> <p></p> <p></p> <p>It is also possible to use external LEDs for the illumination instead of the internal flash LED. This is described here</p>"},{"location":"Installation/#2-firmware","title":"2. Firmware","text":""},{"location":"Installation/#web-installer","title":"Web Installer","text":"<p>There is a Web Installer available which will work right out of the web browser Edge and Chrome. You can access it with the following link: Web Installer</p> <p>This is the preferred way for beginners as it also allows access to the USB Log:</p> <p></p>"},{"location":"Installation/#manual-flashing","title":"Manual Flashing","text":""},{"location":"Installation/#files","title":"Files","text":"<p>Grab the firmware from the</p> <ul> <li>Releases page (Stable, tested versions), or the</li> <li>Automatically build development branch (experimental, untested versions). Please have a look on Living on the Edge first!</li> </ul> <p>You need:</p> <ul> <li>partitions.bin</li> <li>bootloader.bin</li> <li>firmware.bin</li> </ul>"},{"location":"Installation/#flashing-using-the-flash-tool-from-espressif-gui","title":"Flashing using the Flash Tool from Espressif (GUI)","text":"<p>Get the Flash Download Tool from Espressif.</p> <p>Download and extract the Flash tool, after starting choose \"Developer Mode\", then \"ESP32-DownloadTool\" and you are in the setup of the flashing tool. Connect the ESP32-CAM with the USB-UART connection and identify the COM-Port. </p> <p>Warning</p> <p>If you are re-flashing the code again, it is strongly recommended to erase the flash memory before flashing the firmware. Especially if you used OTA in between, which might cause remaining information on the flash, to still boot from an old image in the OTA-area, which is not erased by a normal flash.</p> <p>But your ESP32 in bootloader mode and push start, then it will identify the board and you can configure the bin-configuration according to the following table:</p> Filename Offset bootloader.bin 0x1000 partitions.bin 0x8000 firmware.bin 0x10000 <p></p>"},{"location":"Installation/#flashing-using-the-python-based-esptool-console","title":"Flashing using the Python based esptool (Console)","text":"<p>For this you need a python environment (e.g. Anaconda in Win10).  Here you need to install the esptool:</p> <pre><code>pip install esptool\n</code></pre> <p>Then connect the ESP32 with the USB-UART connector to the system, put it in boot mode and with the following command you can erase the flash and flash bootloader, partitions and firmware in two steps:</p> <pre><code>esptool erase_flash\nesptool write_flash 0x01000 bootloader.bin 0x08000 partitions.bin 0x10000 firmware.bin\n</code></pre> <ul> <li>Maybe you need to specify the COM-port if it is not detected by default.</li> <li>If the erase command throws the error <code>A fatal error occurred: ESP32 ROM does not support function erase_flash.</code>, your <code>esptool</code> might be too old, see https://techoverflow.net/2022/02/08/how-to-fix-esp32-a-fatal-error-occurred-esp32-rom-does-not-support-function-erase_flash/</li> </ul> <p>With some Python installations this may not work and you\u2019ll receive an error, try <code>python -m pip install esptool</code> or <code>pip3 install esptool</code>.</p> <p>Further recommendations can be found on the espressif webpage.</p>"},{"location":"Installation/#3-sd-card","title":"3. SD Card","text":"<p>The software expects an SD card prepared with certain directory and file structure in order to work properly. SD card most top directory should look like this:</p> <p> </p> <p>This initial setup needs only to be done once as further updates (Firmware as well as SD card content) are possible with the Over-The-Air Update mechanism.</p>"},{"location":"Installation/#notes","title":"Notes","text":"<ul> <li>Due to the limited availability of GPIOs (OV2640, Flash-Light, PSRAM &amp; SD card) the communication mode to the SD card is limited to 1-line SD-Mode. It showed up, that this results in problems with very large SD-Cards (64GB, sometimes 32 GB) and some no name low cost SD-cards.</li> <li>There must be no partition table on the SD-card (no GPT, but only MBR for the single partition)</li> <li>Following setting are necessary for formatting the SD-card: SINGLE PARTITION, MBR, FAT32 - 32K.  NOT exFAT</li> <li>Some ESP32 devices share their SD-card and/or camera GPIOs with the pins for TX and RX. If you see errors like \u201cFailed to connect\u201d then your chip is probably not entering the bootloader properly. Remove the respective modules temporarily to free the GPIOs for flashing. You may find more information about troubleshooting on the homepage of Espressif.</li> </ul> <p>The ESP32 indicates problems with the SD card during startup with a fast, endless blinking. In this case, please try another SD card. </p>"},{"location":"Installation/#manual-setup-with-an-sd-card-reader-on-a-pc","title":"Manual Setup with an SD Card Reader on a PC","text":"<ol> <li>Take the <code>AI-on-the-edge-device__manual-setup__*.zip</code> from the Release page.</li> <li>Open it and extract the <code>sd-card.zip</code>.</li> <li>Open it and extract all files onto onto your SD card.</li> <li>On the SD card, open the <code>wlan.ini</code> file and configure it as needed:<ul> <li>Set the corresponding SSID and password</li> <li>The other parameters are optional</li> </ul> </li> </ol> <p>!!! Note       The device provides a File Server which can be used to show, edit or delete the files on the SD card. For security reasons, the <code>wlan.ini</code> file is excluded from this and is hidden from external access to protect the password.</p> <p>After this, you can insert the SD card into the ESP32 board and start it.</p>"},{"location":"Installation/#remote-setup-using-the-built-in-access-point","title":"Remote Setup using the built-in Access Point","text":"<p>On startup of the ESP32, it checks if the <code>wlan.ini</code> or the <code>config/config.ini</code> are available on the SD card. If not, the ESP32 switches to a special mode. In this mode, it provides a Wifi Access Point which can be used to add the missing <code>wlan.ini</code> or the <code>config/config.ini</code> file.</p> <ol> <li>Take the <code>AI-on-the-edge-device__remote-setup__*.zip</code> from the Release page.</li> <li> <p>Connect to Access Point of the device. The SSID is \"AI-on-the-Edge\" and you can access it without any password:</p> <p></p> <p>The device has the following fixed IP: http://192.168.4.1.</p> </li> <li> <p>Upload initial configuration to SD card</p> <p></p> <p>Use the <code>select file</code> and <code>upload</code> button to start the upload. A warning will show up if you have chosen a possible wrong file (without default configuration).</p> </li> <li> <p>Store WLAN access information.</p> <p>After the upload, a new page will be shown:</p> <p></p> <p>Enter your SSID and password.</p> <p>Note</p> <p>Only basic settings are supported. If you need advanced configuration (fixed ip, ...), you need to use the manual setup as documented above.</p> <p>Warning</p> <ul> <li>Carefully check your wifi settings. To change them later on, you need to take out the SD card and edit the <code>wlan.ini</code> manually (or delete it and start again).</li> <li>The information is transferred without encryption!</li> </ul> <p>Finish the step by pushing <code>Write wlan.ini</code></p> </li> <li> <p>Reboot</p> <p>The final step is the reboot:</p> <p></p> <p>Warning</p> <p>It will take up to 3 minutes. Afterwards you can find your device in the local network. Check your router for the IP. You can find it also in the USB Console output.</p> </li> </ol>"},{"location":"Installation/#4-initial-startup","title":"4. Initial Startup","text":"<p>After the firmware is flashed and the SD card is setup properly, you can start it. After power on the connection status is indicated by 3x blinking of the red on board LED.</p> <p>WLAN-Status indication:</p> <ul> <li>5 x fast blinking (&lt; 1 second): connection still pending</li> <li>3 x slow blinking (1 second on/off): WLAN connection established</li> </ul> <p>Note: It is normal that at first one or two times a pending connection is indicated.</p>"},{"location":"Integration-Home-Assistant/","title":"Integration into Home Assistant","text":"<p>There are 3 ways to get the data into your Home Assistant:</p> <ol> <li>Using MQTT (Automatically Setup Entities using Home Assistant MQTT Discovery)</li> <li>Using MQTT (Manually Setup Entities)</li> <li>Using REST calls</li> </ol> <p>The first one is the easier way if you already have MQTT in use.</p>"},{"location":"Integration-Home-Assistant/#using-mqtt-automatically-setup-entities-using-home-assistant-mqtt-discovery","title":"Using MQTT (Automatically Setup Entities using Home Assistant MQTT Discovery)","text":"<p>Starting with Version <code>&gt;12.0.1</code>, AI-on-the-edge-devices support Home Assistant Discovery.</p> <ol> <li>Check here to learn more about it and how to enable it in Homeassistant.</li> <li> <p>You also have to enable it in the MQTT settings of your device:</p> <p></p> <p>Make sure to select the right Meter Type to get the right units!</p> </li> </ol> <p>On the next start of the device, it will send discovery topics and Home Assistant should pick them up and show them under <code>Settings &gt; Integrations &gt; MQTT</code>:</p> <p> </p>"},{"location":"Integration-Home-Assistant/#using-mqtt-manually-setup-entities","title":"Using MQTT (Manually Setup Entities)","text":"<p>First make sure with an MQTT client (for example MQTT Explorer) that MQTT works as expected and to get a list of the available topics!</p> <p>Then add a sensor for each property:</p> <pre><code>mqtt:\n  sensor:\n    - state_topic: \"wasserzaehler/main/value\"\n      name: \"Watermeter Value\"\n      unique_id: watermeter_value\n      unit_of_measurement: 'm\u00b3'\n      state_class: total_increasing\n      device_class: water # Needs Home Assistant 2022.11!\n      icon: 'mdi:water-pump'\n      availability_topic: wasserzaehler/connection\n      payload_available: connected\n      payload_not_available: connection lost\n\n    - state_topic: \"wasserzaehler/main/rate\"\n      name: \"Watermeter Rate\"\n      unique_id: watermeter_rate\n      unit_of_measurement: 'm\u00b3/min'\n      state_class: measurement\n      device_class: water # Needs Home Assistant 2022.11!\n      icon: 'mdi:water-pump'\n      availability_topic: wasserzaehler/connection\n      payload_available: connected\n      payload_not_available: connection lost\n\n    - state_topic: \"wasserzaehler/main/error\"\n      name: \"Watermeter Error\"\n      unique_id: watermeter_error\n      icon: \"mdi:water-alert\"\n      availability_topic: wasserzaehler/connection\n      payload_available: connected\n      payload_not_available: connection lost    \n\n    - state_topic: \"wasserzaehler/uptime\"\n      name: \"Watermeter Uptime\"\n      unique_id: watermeter_uptime\n      unit_of_measurement: 's'\n      state_class: measurement\n      device_class: duration\n      entity_category: diagnostic\n      icon: \"mdi:timer-outline\"\n      availability_topic: wasserzaehler/connection\n      payload_available: connected\n      payload_not_available: connection lost\n</code></pre> <p>If you run the discovery once, you can also extract the information from there (MQTT Info, untested):</p> <pre><code>mqtt: # Extracted form the Discovery but untested!\n  sensor:\n      - name: Value\n        unique_id: wasserzaehler-main_value\n        icon: mdi:gauge\n        state_topic: wasserzaehler/main/value\n        unit_of_measurement: m\u00b3\n        device_class: water\n        state_class: total_increasing\n        availability_topic: wasserzaehler/connection\n        payload_available: connected\n        payload_not_available: connection lost\n</code></pre> <p>If you want to convert the <code>m\u00b3</code> to <code>l</code>, use a template sensor:</p> <pre><code>template:\n  - sensor:\n    - name: \"Watermeter in l\"\n      unique_id: watermeter_in_l\n      icon: \"mdi:gauge\"\n      state: \"{{ states('sensor.watermeter_value')|float(default=0) * 1000 }}\" # Convert 1 m3 =&gt; 1000 l\n      unit_of_measurement: l\n      availability: \"{{ states('sensor.watermeter_value') not in ['unknown', 'unavailable', 'none'] }}\"\n</code></pre> <p>If you you want to have the consumption per day, you can use an Utility Meter. it is a helper and can be used to reset the total increasing values once a day</p> <pre><code>utility_meter:\n  utility_meter_gas_per_day:\n    source: sensor.gasmeter_value\n    cycle: daily\n\n  utility_meter_water_per_day:\n    source: sensor.watermeter_value\n    cycle: daily\n</code></pre> <p>Note that you also can add it using the UI.</p>"},{"location":"Integration-Home-Assistant/#examples","title":"Examples","text":""},{"location":"Integration-Home-Assistant/#statistics-graph","title":"Statistics Graph","text":"<p>Creating Statistics Graphs (e.g. usage per day) is easy using the Energy Dashboard: </p> <p>Note that there seems to be a bug in the graph, see https://github.com/home-assistant/frontend/issues/13995!</p>"},{"location":"Integration-Home-Assistant/#influxdb-graphs","title":"InfluxDb Graphs","text":"<p>See also Influx-DB.</p> <p>If you have setup InfluxDB already, it is also possible to fetch statistics from there, e.g. daily usage:</p> <pre><code>from(bucket: \"HomeAssistant\")\n|&gt; range(start: v.timeRangeStart, stop: v.timeRangeStop)\n  |&gt; filter(fn: (r) =&gt; r[\"entity_id\"] == \"wasserverbrauch_tag\")\n  |&gt; filter(fn: (r) =&gt; r[\"_field\"] == \"value\")\n  |&gt; timeShift(duration: -1d)\n  |&gt; aggregateWindow(every: 1d, fn: max, createEmpty: false)\n  |&gt; yield(name: \"mean\")\n</code></pre> <p></p>"},{"location":"Integration-Home-Assistant/#using-rest","title":"Using REST","text":"<p>When using REST, Home Assistant has to periodically call an URL on the ESP32 which in return provides the requested data.</p> <p>See REST API for a list of available URLs.</p> <p>The most practical one is the <code>json</code> entrypoint which provides the most relevant data JSON formatted: <code>http://&lt;IP&gt;/json</code> This would return:</p> <pre><code>{\n\"main\":\n  {\n    \"value\": \"512.3020\",\n    \"raw\": \"0512.3020\",\n    \"error\": \"no error\",\n    \"rate\": 0.000000,\n    \"timestamp\": \"2022-10-02T20:32:06\"\n   [..]\n  }\n}\n</code></pre> <p>To do such a REST call, you need to create a REST sensor:</p> <pre><code>sensor:\n\n- platform: rest\n  name: \"Gasmeter JSON\" \n  resource: http://&lt;IP&gt;/json\n  json_attributes:\n    - main\n  value_template: '{{ value_json.value }}'\n  headers:\n    Content-Type: application/json\n  scan_interval: 60\n\ntemplate:\n  sensor:\n  - name: \"Gasmeter Value from JSON\"\n    unique_id: gas_meter_value_from_json\n    state: \"{{ state_attr('sensor.gasmeter_json','main')['value'] }}\"\n    unit_of_measurement: 'm\u00b3'\n\n  - name: \"Watermeter Value from JSON\"\n    unique_id: water_meter_value_from_json\n    state: &gt;-\n            {{ state_attr('sensor.watermeter_json','main')['value'] | float }}\n    unit_of_measurement: 'm\u00b3'\n    device_class: water\n    state_class: total_increasing\n    icon: mdi:gauge\n\n</code></pre> <p>The 2nd way is to use the html api call from value.html : </p> <p><code>sensor: - platform: rest   resource: http://&lt;IP&gt;/value.html   name: cold_water    unique_id: cold_water_from_rest   unit_of_measurement: \"L\"   device_class: water   state_class: total_increasing   icon: mdi:gauge   scan_interval : 120</code></p> <p>See also https://community.home-assistant.io/t/rest-sensor-nested-json/243420/9</p>"},{"location":"Integration-Home-Assistant/#photo","title":"Photo","text":"<p>REST can also be used to show the photo of the last round:</p> <p></p> <p>To access it, use <code>http://&lt;IP&gt;/img_tmp/alg_roi.jpg</code> resp <code>http://&lt;IP&gt;/img_tmp/raw.jpg</code>.</p>"},{"location":"Learn-models-with-your-own-images/","title":"Learn a model with your own images","text":"<p>Once you have collected and selected your own images (see Collect images to improve the models), you can train your very own model with them.</p> <p>This is an optional step and only suggested for advances users!</p> <p>For training the model you will need a python and Jupyter installation.</p> <p>All current labeled images you can find under ziffer_sortiert_raw</p>"},{"location":"Learn-models-with-your-own-images/#dig-class11-models-digits","title":"dig-class11 models (digits)","text":"<p>Fork and checkout neural-network-digital-counter-readout.</p> <p>Install all requirements for running the notebooks.</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>Put your labeled images into <code>/ziffer_sortiert_raw</code> folder and run</p> <ol> <li>Image_Preparation.ipynb</li> <li>Train_CNN_Digital-Readout-Small-v2.ipynb</li> </ol> <p>It creates a dig-class11_xxxx_s2.tflite model, you can upload to the <code>config</code> folder on your device and test it. </p>"},{"location":"Learn-models-with-your-own-images/#dig-class100-dig-cont-models-digits","title":"dig-class100 / dig-cont models (digits)","text":"<p>Fork and checkout neural-network-digital-counter-readout.</p> <p>All labeled images you can find under Images</p> <p>Install all requirements for running the notebooks.</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>Put your labeled images into <code>images/collected/&lt;typeofdevice&gt;/&lt;your_short&gt;/</code></p> <p>Run dig-class100-s2.ipynb. The model to upload to your device you can find under '/output'.</p>"},{"location":"Learn-models-with-your-own-images/#ana-class100ana-cont-models-analog-pointers","title":"ana-class100/ana-cont models (analog pointers)","text":"<p>Fork and checkout neural-network-analog-needle-readout.</p> <p>All labeled images you can find under data_raw_all</p> <p>Install all requirements for running the notebooks.</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>Put your labeled images into <code>images/collected/&lt;typeofdevice&gt;/&lt;your_short&gt;/</code></p> <p>After every adding of images you need to run Image_Preparation.ipynb before you train the models.</p> <p>Run Train_CNN_Analog-Readout_100-Small1_Dropout.ipynb and/or Train_CNN_Analog-Readout_Version-Small2.ipynb. The model to upload to your device you can find in the project folder.</p>"},{"location":"Learn-models-with-your-own-images/#share-your-images","title":"Share your images","text":"<p>If the results are good you can share the images as pull-request. Please images only!</p> <p>See Share your images for details.</p>"},{"location":"MQTT-API/","title":"MQTT API","text":"<p>The device is capable to register to a MQTT broker to publish data and subscribe to specific topics.</p> <p>Note</p> <p>Only MQTT v3.1.1 is supported.</p> <p>The MQTT service has to be enabled and configured properly in the device configuration via web interface (<code>Settings</code> -&gt; <code>Configuration</code> -&gt; section <code>MQTT</code>)</p> <p>The following parameters have to be defined: * URI * MainTopic (optional, if not set, the hostname is used) * ClientID (optional, if not set, <code>AIOTED-</code> + the MAC address gets used to make sure the ID is unique) * User (optional) * Password (optional) * RetainFlag (optional)</p>"},{"location":"MQTT-API/#published-topics","title":"Published topics","text":""},{"location":"MQTT-API/#status","title":"Status","text":"<p>The following overhead data are available under the main topic (i.e. <code>watermeter</code>):</p> Topic Description <code>watermeter/MAC</code> The MAC address of the ESP module. <code>watermeter/IP</code> The IP address of the ESP module. <code>watermeter/Hostname</code> The network host name of the ESP module. <code>watermeter/Interval</code> The round interval as configured during setup or in Parameters -&gt; Interval. <code>watermeter/Connection</code> Network connection status. <code>watermeter/Uptime</code> Seconds up since last boot. <code>watermeter/FreeMem</code> Free memory in kB. <code>watermeter/wifiRSSI</code> Quality of WiFi signal. <code>watermeter/CPUTemp</code> Temperature of the ESP CPU in degrees celsius."},{"location":"MQTT-API/#result","title":"Result","text":"<p>The following calculation data are available under the sup-topic <code>main</code> (i.e. <code>watermeter/main</code>):</p> Topic Description <code>watermeter/main/error</code> Informs about the flow status. On success, the value is <code>no error</code>. <code>watermeter/main/raw</code> The value before performing post processing. <code>watermeter/main/value</code> The value after performing post processing. <code>watermeter/main/rate</code> How much flow was consumed in one minute. <code>watermeter/main/rate_per_time_unit</code> How much flow was consumed in one minute. The time unit gets set with the Home Assistant Discovery, e.g. <code>h</code> (hours) or <code>m</code> (minutes). <code>watermeter/main/changeabsolut</code> Difference between the previous and actual read value. <code>watermeter/main/rate_per_digitalization_round</code> How much flow was consumed in one minute. <code>watermeter/main/timestamp</code> Timestamp of the last valid reading (equal to timestamp of previous value) <code>watermeter/main/Status</code> Informs about the last performed step of the watermeter (i.e. <code>Flow finished</code>). <code>watermeter/main/json</code> This is a JSON formatted object containing the following values: <code>value</code>, <code>raw</code>, <code>pre</code>, <code>error</code>, <code>rate</code>, <code>timestamp</code>."},{"location":"MQTT-API/#gpio","title":"GPIO","text":"<p><code>MainTopic</code>/{GPIO topic}, e.g. <code>watermeter/GPIO/GPIO12</code></p>"},{"location":"MQTT-API/#gpiogpiopinnumber","title":"GPIO/GPIO{PinNumber}","text":"<p>Depending on device configuration (<code>Settings</code> --&gt; <code>Configuration</code> --&gt; section <code>GPIO</code>)</p>"},{"location":"MQTT-API/#subscribed-topics","title":"Subscribed topics","text":"<p><code>MainTopic</code>/{subscribed topic}, e.g. <code>watermeter/ctrl/flow_start</code></p>"},{"location":"MQTT-API/#control","title":"Control","text":""},{"location":"MQTT-API/#ctrlflow_start","title":"ctrl/flow_start","text":"<p>Trigger a flow start by publishing to this topic.</p> <p>Payload:</p> <ul> <li>any character, length &gt; 0</li> </ul>"},{"location":"MQTT-API/#ctrlset_prevalue","title":"ctrl/set_prevalue","text":"<p>Note</p> <p>This feature is available since version 15.2.0.</p> <p>Set the last valid value (previous value) to given value or the actual RAW value. Payload needs to be provided in JSON notation.</p> <p>Payload:</p> <ul> <li> <p>Set to given value (value &gt;= 0): <code>{\"numbersname\": \"&lt;NUMBERSNAME&gt;\", \"value\": &lt;VALUE&gt;}</code></p> <ul> <li><code>\"numbersname\":</code>Provide name of number sequence, e.g. <code>\"main\"</code> </li> <li><code>\"value\":</code> provide the value to be set, eg. <code>12345.67890</code></li> </ul> </li> <li> <p>Set to actual RAW value (value &lt; 0, a valid RAW value is mandatory): <code>{\"numbersname\": \"&lt;NUMBERSNAME&gt;\", \"value\": -1}</code></p> <ul> <li><code>\"numbersname\":</code> Provide name of number sequence, e.g. <code>\"main\"</code> </li> <li><code>\"value\":</code> Provide any negative number</li> </ul> </li> </ul>"},{"location":"MQTT-API/#gpiogpiopinnumber_1","title":"GPIO/GPIO{PinNumber}","text":"<p>Depending on device configuration (<code>Settings</code> --&gt; <code>Configuration</code> --&gt; section <code>GPIO</code>)</p>"},{"location":"Neural-Network-Types/","title":"Neural Network Types","text":"<p>Note</p> <p>For an overview, see Choosing the Model.</p> <p>This section is describing the different types of neural networks, that are used with the AI-on-the-edge approach and gives an introduction on how and where to use them. </p>"},{"location":"Neural-Network-Types/#overview-neural-network-type","title":"Overview neural network type","text":"<p>There are two types of input:</p> <ul> <li> <p>digits with rolling number (top town)</p> </li> <li> <p>analog pointers (clockwise rotating pointer) </p> </li> </ul> <p>There are two types of neural networks:</p> <ul> <li>classification networks with discrete output neurons for each result class:</li> <li>11 classes for digits (0, 1, ... 8, 9 + \"Not-A-Number\")</li> <li>100 classes for digits or analog pointers (0.1, 0.2, 0.3, ... , 9.7, 9.8, 9.9)</li> <li>continuous output networks with a continuous output in the interval [0, 10[</li> </ul> <p>No setting of the type in the firmware is necessary. The type can detect by the output structure automatically.</p> <p>Warning</p> <ul> <li>It is very important to choose the right network type (digits or analog pointers).    Technically a wrong network will work and create output, but that would be totally arbitrary</li> <li>Not all type of pointers are trained in all networks.</li> <li>For the 11 classes digits network there many different types of digits trained. The reason is, that you 1) only need 20-30 training images and 2) the data collection is ongoing much longer</li> <li>For the continuous and 100 classes network especially for the digits, there are only a few types of digits trained up to now</li> <li>Therefore sometimes for the digits it is more effective to choose the simpler 11 classes network type (= default). </li> </ul>"},{"location":"Neural-Network-Types/#naming-convention","title":"Naming convention","text":"Classification11 classes0, 1, ... 9 + \"N\" Classification100 classes0.0, 0.1, ... 9.9 ContinuousInterval[0, 10[ Digits dig-class11_XXX.tflite dig-class100_XXX.tflite dig-cont_XXX.tflite Analog Pointers ana-class100_XXX.tflite ana-cont_XXX.tflite <p>XXX contains the versioning and a parameter for different sizes with the following naming:</p> <p>XXX = versioning_sY</p> <ul> <li> <p>versioning = version or in newer networks the training data</p> </li> <li> <p>Y = Neural network size (typically s1, s2, ..., s4). Whereas s1 is the maximum sized neural network and s4 is the smallest.</p> </li> </ul> <p>Optional the naming ends with an \"_q\" to signal, that the tflite file has been quantized (size reduction with minimum accuracy loss).</p> <p>Example: <code>dig-class11_1410_s2_q.tflite</code></p> <ul> <li>Classification network for digits with 11 classes (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, N)</li> <li>Version 1410 = 14.1.0</li> <li>s2 = Size 2 (Medium)</li> <li>q = Quantized Version</li> </ul>"},{"location":"Neural-Network-Types/#overview-of-trained-types-and-details","title":"Overview of trained types and details","text":""},{"location":"Neural-Network-Types/#analog-pointer-ana-cont_xxxtflite-ana-class100_xxxtflite","title":"Analog Pointer (\"ana-cont_XXX.tflite\" &amp; \"ana-class100_XXX.tflite\")","text":"<p>This is to transfer the direction of a pointer into a continuous number between 0 and 1, whereas 0 (=1) is the upwards position (12 o'clock), 0.25 corresponds to the 3 o'clock positions and so on. This network is a envelop for all different types of pointers. Currently there are no dedicated network trainings for specific types of pointers.</p> <p>There are two types of network structure, currently both are supported. The \"class100\" is a pure classification network, that might need a bit more accuracy in the labeling. \"cont\" is a no classic approach with a continuous output off only 2 neurons (details see below).</p>"},{"location":"Neural-Network-Types/#types-of-counters-trained","title":"Types of counters trained:","text":""},{"location":"Neural-Network-Types/#training-data-needs","title":"Training data needs","text":"<ul> <li>Quadratic images, minimum size: 32x32 pixel</li> <li>Typically 100 - 200 images with a resolution of 1/100 of the full rotation (every 0.1 value or 3.6\u00b0)</li> <li>Naming: x.y_ARBITRARY.jpg, where x.y = value 0.0 ... 9.9</li> </ul>"},{"location":"Neural-Network-Types/#cnn-technical-details","title":"CNN Technical details:","text":""},{"location":"Neural-Network-Types/#input","title":"Input","text":"<ul> <li>32 x 32 RGB images</li> </ul>"},{"location":"Neural-Network-Types/#output","title":"Output","text":"<ul> <li>ana-cont_XXX.tflite:</li> <li>2 neurons with output in range [-1, 1] - representing a sinus / cosine encoding of the angle</li> <li> <p>needs to be converted to angle with arctan-hyperbolic function</p> </li> <li> <p>ana-class100_XXX.tflite</p> </li> <li>100 neurons representing the classes from 0.0, 0.1, ... 9.8, 9.9</li> </ul>"},{"location":"Neural-Network-Types/#digits-with-11-classes-dig-class11_xxxtflite","title":"Digits with 11 classes (\"dig-class11_XXX.tflite\")","text":"<p>The digit type is a classical classification network, with 11 classes representing the numbers 0, 1, ... 9 and the special class \"N\". It is trained for the rolling ring of gas and electric meters. As there is sometime a status between two images, the special class \"N\" is representing Not-A-Number for the case, that the image cannot be unique classified to one number e.g. because it is between two digits. For this type the lowest amount of training data per type is needed, resulting in a large variety of type being already part of the training set.</p>"},{"location":"Neural-Network-Types/#types-of-counters-trained_1","title":"Types of counters trained:","text":""},{"location":"Neural-Network-Types/#training-data-needs_1","title":"Training data needs","text":"<ul> <li>RGB images, with minimum size: 20x32 pixel</li> <li> <p>Typically 10 - 20 images (1-2 for each digit and an arbitrary number for the \"N\" class</p> </li> <li> <p>Naming: x_ARBITRARY.jpg, where x = value 0 ... 9 + N</p> </li> </ul>"},{"location":"Neural-Network-Types/#cnn-technical-details_1","title":"CNN Technical details:","text":""},{"location":"Neural-Network-Types/#input_1","title":"Input","text":"<ul> <li>20 x 32 RGB images</li> </ul>"},{"location":"Neural-Network-Types/#output_1","title":"Output","text":"<ul> <li>11 neurons for image classification (last layer normalized to 1)</li> <li>Neuron 0 to 9 represent the corresponding numbers \"0\" to \"9\"</li> <li>Neuron 10 represents the \"Not-A-Number\" class, telling, that the image is not uniquely classified</li> </ul>"},{"location":"Neural-Network-Types/#digits-with-rolling-results-dig-class100_xxxtflite-dig-cont_xxxtflite","title":"Digits with rolling results (\"dig-class100_XXX.tflite\" &amp; \"dig-cont_XXX.tflite\")","text":"<p>This type of network tries to overcome the problem, that there are intermediate values, when a rolling digit is between two numbers. Previous this was the \"N\" class. In this network type, there are also sub-digit values trained, so that the intermediate state can be used as additional information for the algorithms. </p>"},{"location":"Neural-Network-Types/#types-of-counters-trained_2","title":"Types of counters trained:","text":""},{"location":"Neural-Network-Types/#training-data-needs_2","title":"Training data needs","text":"<ul> <li>RGB images, with minimum size: 20x32 pixel</li> <li> <p>Typically 100 - 200 images (1-2 for each possible position) </p> </li> <li> <p>Naming: x.y_ARBITRARY.jpg, where x.y = 0.0, 0.1, ... 9.9 representing the intermediate state</p> </li> </ul>"},{"location":"Neural-Network-Types/#cnn-technical-details_2","title":"CNN Technical details:","text":""},{"location":"Neural-Network-Types/#input_2","title":"Input","text":"<ul> <li>20 x 32 RGB images</li> </ul>"},{"location":"Neural-Network-Types/#output_2","title":"Output","text":"<ul> <li>dig-cont_XXX.tflite:</li> <li>10 neurons representing the digits 0, 1, ... 9. The intermediate values are represented by weighted normalized values of two neighboring output neurons</li> <li> <p>needs to be converted to angle with arctan-hyperbolic function</p> </li> <li> <p>dig-class100_XXX.tflite</p> </li> <li>100 neurons representing the classes from 0.0, 0.1, ... 9.8, 9.9</li> </ul>"},{"location":"New-Releases-Notification/","title":"Notification about new Releases","text":"<p>Do you want to get notified about a new release? There are several ways for it:</p>"},{"location":"New-Releases-Notification/#github-notifications","title":"Github Notifications","text":"<p>You will need a Github Account for this!</p> <ol> <li>Log into your Github account on Github.</li> <li>Go to AI-on-the-edge-device.</li> <li>On the top right side, click onto <code>Watch</code> and select <code>Custom</code>:      </li> <li>Select <code>Releases</code>.</li> </ol> <p>You will get an email when a new release gets created.</p> <p>See also Github Documentation.</p>"},{"location":"New-Releases-Notification/#codereleaseio","title":"CodeRelease.io","text":"<p>Alternatively or if you do not want to create a Github account, CodeRelease.io can be an alternative.</p> <p>You also have to subscribe with an email address but no account is required.</p>"},{"location":"Parameters/","title":"Parameters","text":"<p>This page lists all available Configuration Parameters. If a parameter or section has a tick box on its left side, you can disable it. In such case the functionality gets disabled respectively the default values will be used.</p> <p>Note</p> <p>This is an auto-generated page! See the README for details!</p>"},{"location":"Parameters/#section-takeimage","title":"Section <code>TakeImage</code>","text":""},{"location":"Parameters/#section-alignment","title":"Section <code>Alignment</code>","text":""},{"location":"Parameters/#section-digits","title":"Section <code>Digits</code>","text":""},{"location":"Parameters/#section-analog","title":"Section <code>Analog</code>","text":""},{"location":"Parameters/#section-postprocessing","title":"Section <code>PostProcessing</code>","text":""},{"location":"Parameters/#section-mqtt","title":"Section <code>MQTT</code>","text":""},{"location":"Parameters/#section-influxdb","title":"Section <code>InfluxDB</code>","text":""},{"location":"Parameters/#section-influxdbv2","title":"Section <code>InfluxDBv2</code>","text":""},{"location":"Parameters/#section-gpio","title":"Section <code>GPIO</code>","text":""},{"location":"Parameters/#section-autotimer","title":"Section <code>AutoTimer</code>","text":""},{"location":"Parameters/#section-datalogging","title":"Section <code>DataLogging</code>","text":""},{"location":"Parameters/#section-debug","title":"Section <code>Debug</code>","text":""},{"location":"Parameters/#section-system","title":"Section <code>System</code>","text":""},{"location":"REST-API/","title":"REST API","text":"<p>Various information is directly accessible over specific REST calls.</p> <p>To use it, just append them to the IP, separated with a <code>/</code>, e.g. <code>http://192.168.1.1/json</code></p> <p>Note: For more detailed information to the REST handler, have a look to the code in the repository: registered handlers</p>"},{"location":"REST-API/#control","title":"Control","text":""},{"location":"REST-API/#flow_start","title":"flow_start","text":"<p>Trigger a flow start (if not running)      + Payload:         - No payload needed</p>"},{"location":"REST-API/#setprevalue","title":"setPreValue","text":"<p>Set the last valid value (previous value) to given value or the actual RAW value.      + Payload:         - Set to given value (value &gt;= 0), e.g. <code>/setPreValue?numbers=main&amp;value=1234.5678</code>            * <code>numbers=</code> Provide name of number sequence, e.g. main            * <code>value=</code> provide the value to be set</p> <pre><code>    - Set to actual RAW value (value &lt; 0, a valid RAW value is mandatory), e.g. `/setPreValue?numbers=main&amp;value=-1`\n       * `numbers=` Provide name of number sequence, e.g. main\n       * `value=` provide yna negative number\n</code></pre>"},{"location":"REST-API/#gpio","title":"GPIO","text":"<ul> <li> <p>Control a GPIO output</p> <ul> <li>The <code>GPIO</code> entrypoint also support parameters:</li> <li><code>/GPIO?GPIO={PinNumber}&amp;Status=high</code></li> <li><code>/GPIO?GPIO={PinNumber}&amp;Status=low</code></li> <li>Example: <code>/GPIO?GPIO=12&amp;Status=high</code></li> </ul> </li> <li> <p>Read a GPIO input </p> <ul> <li>The <code>GPIO</code> entrypoint also support parameters:</li> <li><code>/GPIO?GPIO={PinNumber}</code></li> <li>Example: <code>/GPIO?GPIO=12</code></li> </ul> </li> </ul>"},{"location":"REST-API/#reboot","title":"reboot","text":"<p>Trigger a reboot of the device</p>"},{"location":"REST-API/#mqtt_publish_discovery","title":"mqtt_publish_discovery","text":"<p>Trigger re-sending of the Home Assistant discovery topics.   The topics will get send at the end of the next round.</p>"},{"location":"REST-API/#results","title":"Results","text":""},{"location":"REST-API/#json","title":"json","text":"<p>Show result in JSON syntax   - Example:    <code>{   \"main\":     {       \"value\": \"521.17108\",       \"raw\": \"521.17108\",       \"pre\": \"521.17108\",       \"error\": \"no error\",       \"rate\": \"0.023780\",       \"timestamp\": \"2023-01-13T16:00:42+0100\"     }   }</code></p>"},{"location":"REST-API/#value","title":"value","text":"<p>Show single result values   - The <code>value</code> entrypoint also support parameters:    - <code>http://&lt;IP&gt;/value?all=true&amp;type=value</code>    - <code>http://&lt;IP&gt;/value?all=true&amp;type=raw</code>    - <code>http://&lt;IP&gt;/value?all=true&amp;type=error</code>    - <code>http://&lt;IP&gt;/value?all=true&amp;type=prevalue</code></p>"},{"location":"REST-API/#img_tmprawjpg","title":"img_tmp/raw.jpg","text":"<p>Capture and show a new raw image</p>"},{"location":"REST-API/#img_tmpalgjpg","title":"img_tmp/alg.jpg","text":"<p>Show last aligned image</p>"},{"location":"REST-API/#img_tmpalg_roijpg","title":"img_tmp/alg_roi.jpg","text":"<p>Show last aligned image including ROI overlay</p>"},{"location":"REST-API/#status","title":"Status","text":""},{"location":"REST-API/#statusflow","title":"statusflow","text":"<p>Show the actual step of the flow incl. timestamp   - Example: <code>Take Image (15:56:34)</code></p>"},{"location":"REST-API/#rssi","title":"rssi","text":"<p>Show the WIFI signal strength (Unit: dBm)   - Example: <code>-51</code></p>"},{"location":"REST-API/#cpu_temperature","title":"cpu_temperature","text":"<p>Show the CPU temperature (Unit: \u00b0C)   - Example: <code>38</code></p>"},{"location":"REST-API/#sysinfo","title":"sysinfo","text":"<p>Show system infos in JSON syntax   - Example: <code>[{\"firmware\": \"\",\"buildtime\": \"2023-01-25 12:41\",\"gitbranch\": \"HEAD\",\"gittag\": \"\",\"gitrevision\": \"af13c68+\",\"html\": \"Development-Branch: HEAD (Commit: af13c68+)\",\"cputemp\": \"64\",\"hostname\": \"WaterMeterTest\",\"IPv4\": \"192.168.xxx.xxx\",\"freeHeapMem\": \"2818330\"}]</code></p>"},{"location":"REST-API/#starttime","title":"starttime","text":"<p>Show starttime   - Example: <code>20230113-154634</code></p>"},{"location":"REST-API/#uptime","title":"uptime","text":"<p>Show uptime   - Example: <code>0d 00h 15m 50s</code></p>"},{"location":"REST-API/#camera","title":"Camera","text":""},{"location":"REST-API/#lighton","title":"lighton","text":"<p>Switch the camera flashlight on </p>"},{"location":"REST-API/#lightoff","title":"lightoff","text":"<p>Switch the camera flashlight off</p>"},{"location":"REST-API/#capture","title":"capture","text":"<p>Capture a new image (without flashlight)</p>"},{"location":"REST-API/#capture_with_flashlight","title":"capture_with_flashlight","text":"<p>Capture a new image with flashlight</p>"},{"location":"REST-API/#stream","title":"stream","text":"<p>Stream a live video of the camera.</p> <p>It has a slow refresh rate of only 2 FPS to avoid stressing the system. Flow processing continues to work in the background, albeit possibly a bit slower.</p> <p>When the <code>flashlight</code> parameter is set, it turns on the flaslight. Both <code>http://&lt;IP&gt;/stream?flashlight=true</code> and <code>http://&lt;IP&gt;/stream?flashlight</code> turn on the flashlight.</p> <p>LIMITATION: To avoid using extra memory, no additional dedicated stream webserver is implemented for this feature (instead, the web interface server is reused in a kind of \"blocking way\"). This means that either the web interface is fully functional or the stream is active, but not both at the same time. However, this is sufficient for the intended use case.</p>"},{"location":"REST-API/#save","title":"save","text":"<p>Save a new image to SD card   - The <code>save</code> entrypoint also support parameters:    - <code>http://&lt;IP&gt;/save?filename=test.jpg&amp;delay=1000</code></p>"},{"location":"REST-API/#logs","title":"Logs","text":""},{"location":"REST-API/#log","title":"log","text":"<p>Last part of todays log (last 80 kBytes))</p>"},{"location":"REST-API/#logfileact","title":"logfileact","text":"<p>Full log of today</p>"},{"location":"REST-API/#loghtml","title":"log.html","text":"<p>Opens the log html page</p>"},{"location":"REST-API/#diagnostics","title":"Diagnostics","text":""},{"location":"REST-API/#heap","title":"heap","text":"<p>print relevant memory (heap) information   - Example: <code>Heap info: Heap Total: 1888926 | SPI Free: 1827431 | SPI Larg Block: 1802240 | SPI Min Free: 758155 | Int Free: 61495 | Int Larg Block: 55296 | Int Min Free: 36427</code></p>"},{"location":"REST-API/#prometheusopenmetrics","title":"Prometheus/OpenMetrics","text":""},{"location":"REST-API/#metrics","title":"metrics","text":"<p>Provides a set of metrics that can be scraped by prometheus. See Prometheus/OpenMetrics for details.</p>"},{"location":"ROI-Configuration/","title":"ROIs (Regions of Interest)","text":"<p>Notes</p> <p>You are using a neural network approach which is trained to fit as many different type of meters as possible. The accuracy will never be 100%. It is normal to see a missing reading once in a while.  There are several precautions to detect this. For details see the section <code>PostProcessing</code> on the configuration page.</p> <p>The most critical components for an accurate detection are:</p> <ol> <li> <p>Correct setting of the Regions Of Interest (ROIs) for detection of the image.</p> <p>This must be done manually for each device/installation!</p> </li> <li> <p>Using a well trained Model.</p> <p>Have a look on the Digital Counters resp. Analog Needles to check if your types are contained. If your number types are not contained, you should take the effort to record them so we can add them to the training data. See Collect images to improve the models on how to collect new training data.</p> </li> </ol>"},{"location":"ROI-Configuration/#precondition","title":"Precondition","text":"<p>Please make sure to have:</p> <ol> <li>Setup your camera properly and taken a good Reference Image.</li> <li>Selected good Alignment References.</li> </ol>"},{"location":"ROI-Configuration/#define-the-rois","title":"Define the ROIs","text":"<p>For each digit or analog pointer, a ROI must be defined.</p> <p>You can even have multiple independent Numbers (eg. electerical meters mostly have 2 numbers for the high and low tariff). </p> <p>Depending if you have only one of those types, you can enable/disable <code>(1)</code> it on the top left corner: </p> <p></p> <p>You can switch between the individual ROIs with the Drop down box <code>(2)</code>. If you need additional ROIs or delete them you can do this with the control at <code>(3)</code>. Like for the Alignment References, you can change the position, size and name of a ROI in the text fields or define them via drag and drop through the mouse button.  Make sure the ROIs are in the right order, matching the significance of a digit/analog counter!</p> <p>Warning</p> <p>The order of the ROIs defines how the individual digits are combined to the total number. The first ROI is the digit with the highest order (left side), then the second and so on. You can control the order in the selector tab and change it with the buttons <code>\"move Next\"</code> or <code>\"move Previous\"</code>.</p> <p>In most cases digits are ordered equidistantly (have the same distance between each other) and have the same size. Because of this, the Web Interface keeps their sizes and distance the same. If you need individual sizes or distances, untick the settings <code>(4)</code>.</p> <p>In almost all cases the sizes and <code>y</code> values should be identical! The ratio between <code>x</code> and <code>y</code> might need adjustment. But make sure it is the same for all digits.</p> <p>Same for the analog counters, the sizes should be identical and the <code>x</code> and <code>y</code> as well.</p> <p>Note</p> <p>Don't forget to save the settings with \"Save\" and do not reboot at this stage.</p>"},{"location":"ROI-Configuration/#analog-counters","title":"Analog Counters","text":"<p>For analog counters the ROI setting is rather straight forward as the meter is usually quadratic with a clear center. The circle should exactly fit to the outer size of the meter and the cross should be in the middle of the pointer.</p> <p>Here is an example with the details for the ROI <code>ana1</code>: </p> <p></p>"},{"location":"ROI-Configuration/#digits","title":"Digits","text":"<p>For the Digital Meters it is a little bit more complicated, as there are different options of digital models which can be choosen.</p>"},{"location":"ROI-Configuration/#correct-size-for-roi","title":"Correct Size for ROI","text":"<p>First of all, choose the right size of the ROI. The configuration of ROIs differs a bit on the selected model (see below). </p> <p>If you are in the initial setup, the model will be selectable in the next step. By default it is a <code>dig-cont</code> resp. <code>ana-cont</code> model.</p> <p>In Model Selection you find the differences between the different available models. Pick the one you think fits best your purpose. If you don't get to good result, try another model.</p> <p>Here we only show the different configuration of the ROIs.</p> <ol> <li> <p>Digital Meters with only recognized full digits (<code>0, 1, 2, 3, ... 9</code>)</p> <p>Suggested Model: <code>dig-class11-*.tfl</code></p> <p>Advantage: broad variety of types included in the training.</p> <p>Disadvantage: partially rotated numbers cannot be detected.</p> </li> <li> <p>Digital Meters with sub-digit resolution (<code>0.0, 0.1, 0.2, .... 9.8, 9.9</code>)</p> <p>Suggested Model: <code>dig-cont-*.tfl</code> or <code>dig-class100-*.tfl</code></p> <p>Advantage: partial numbers can be detected and a better post processing is possible.</p> <p>Disadvantage: only limited types of meter types are trained due to the high effort for the training data.</p> </li> </ol>"},{"location":"ROI-Configuration/#how-to-setup-the-digit-rois-perfectly","title":"How to setup the digit ROIs perfectly","text":"<p>Details and the corresponding \"perfect\" setting is explained below. For a first run you can choose the following general settings: </p> <ul> <li>There is an inner and an outer frame for the ROIs. </li> <li>Make the inner frame exactly the size of the number.</li> </ul> Example 1 Example 2 \u2714\ufe0f Okay \u274c Not Okay \u274c Not Okay"},{"location":"ROI-Configuration/#setup-using-dig-class11-models","title":"Setup using <code>dig-class11</code> models","text":"<p><code>dig-class11</code> - Models recognize the complete digit only. Here it is not relevant if the ROI fits the Border of the digit window.</p> <p>For this model, there should be a border of <code>20%</code> of the image size around the number itself. This border is shown in the ROI setup image by the inner thinner rectangle. This rectangle should fit perfectly around the number when the number has not started to rotate to the next position: </p> <p></p> Example 1 Example 2 \u2714\ufe0f Okay \u274c Not Okay \u274c Not Okay <p>If you have perfect alignment and still are not getting satisfying results, most probably your numbers are not part of the training data yet. See Collect images to improve the models on how to collect new training data.</p>"},{"location":"ROI-Configuration/#setup-using-dig-class100-or-dig-cont-models","title":"Setup using <code>dig-class100</code> or <code>dig-cont</code> Models","text":"<p>These models recognize the tenths (fractions) between the numbers. Those models require a different ROI setup; the height must be set differently and more accurately.</p> <p>First, the width can be set like for a <code>dig-class11</code> model, i.e. <code>20%</code> margin left and right.</p> <p></p> <p>The height of the outer rectangle should be set to the upper and lower edge of the number window. To achieve this, you might need to unlock the aspect ratio:</p> <p></p> <p>Here an example:</p> Example 1 \u2714\ufe0f Okay \u274c Not Okay"},{"location":"ROI-Configuration/#saving","title":"Saving","text":"<p>Once you are done,  push <code>Save</code> to persist your setup.</p> <p>A reboot is required to apply the changed configuration!</p>"},{"location":"Reference-Image/","title":"Reference Image","text":"<p>Note</p> <p>The Reference Image is the basis for the coordinate system of the ROIs. Therefore it is very important, to have a well aligned image, that is not rotated. </p> <p>At first an example image is shown. To define a new reference image push the button <code>\"Create new Reference\" (2)</code> and afterwards <code>\"Take Image\" (2)</code>. It might take some seconds for processing, then your actual camera image should be shown. Then play with the provided parameters to get a good result.</p> <p></p>"},{"location":"Reference-Image/#focus","title":"Focus","text":"<p>This is the first time, where you have access to the camera image. It most likely is out of focus and not sharp! Ensure a sharp image of the camera by adjusting the focal length of the ESP OV2640 camera.</p> <p>Note</p> <p>Try to adjust the focus for the clearest possible image!</p> <p>In order to use it for reading a meter, the focal-length  of the OV2640 camera has to be manipulated. By default it only results in sharp image for distance bigger than around <code>~40cm</code> which is not ideal for our purpose.</p> <p>Therefore you need to remove the fixing glue of the OV2640 lens with a sharp knife. After this you can rotate the lens in and out. Rotating it by about a quarter of a turn counterclockwise results in a focus plane shift of about 10cm. You need to figure out your best setting with a little bit of  trial and error for your specific environment.</p> <p>Error</p> <p>Be very carefully when rotating the lens. Best is to held the camera itself with one hand or a plier and rotate the lens with the other hand. Make sure not to rotate the whole camera as this can damage the ribbon cable!</p> <p>Warning</p> <p>This modification will void any warranty, as the sealing of the lens objective is broken!</p> <p>Warning</p> <p>This modification will render the camera unsuitable for general, web-cam type applications unless the focal length is changed back to the original setting.</p> <p></p>"},{"location":"Reference-Image/#correct-horizontal-alignment","title":"Correct Horizontal Alignment","text":"<p>Ensure an exact horizontal alignment of the number:</p> \u2714\ufe0f Okay \u274c Not Okay <p>Warning</p> <p>Updating the reference image also means that all alignment images and ROIs needs to be configured again. Therefore do this step later only with caution.</p> <p>If everything is done, you can save the result with <code>\"Update Reference Image\" (4)</code>.</p> <p>Note</p> <p>A reboot is not required at this point of time.</p> <p>As next you should update the Alignment References.</p>"},{"location":"Reference-Image/#dealing-with-reflections","title":"Dealing with Reflections","text":"<p>Reflections can be caused by the flash LED and make it hard to provide a reliable detection. There are various ways to deal with them:</p> <ul> <li>Attach a diffusor in front of the LED, eg. a filt (Filz) or parchment paper. Also white paper can do the job.</li> <li>Rotate the ESP-CAM so the LED is on another place.</li> <li>Reduce the LED intensity.</li> <li>Use external LED stripes, eg <code>WS2812x</code>.</li> </ul>"},{"location":"Release-creation/","title":"Preparing for Release","text":"<ol> <li>Changelog is merged back from <code>master</code> branch to <code>rolling</code> branch (should be the last step of the previous release creation)</li> <li>All changes are documented in the Changelog in <code>rolling</code> branch.    To get a list of commits, call <code>git log --oneline</code>. Summarize the relevant chnages since the last release.</li> </ol>"},{"location":"Release-creation/#release-creation-steps","title":"Release creation steps","text":"<ol> <li>Merge<code>rolling</code> into <code>master</code> branch</li> <li>Best to wait for the GitHub action to run successfully </li> <li> <p>On <code>master</code> branch tag the version like <code>v11.3.1</code> and don't forget to push it:</p> <p><code>git checkout master  git pull  git tag v14.0.0  git push --tags</code></p> </li> <li> <p>Wait for the GitHub-Action of release creation. After all is done:</p> <ul> <li>the release should be created</li> <li>the artifacts are downloadable from release </li> <li>The documented changes were applied to the release</li> </ul> </li> <li>Merge master back in <code>rolling</code></li> <li>Check that the Web Installer shows the right version. If needed, run he action manually: github.com/jomjol/AI-on-the-edge-device/actions/workflows/manual-update-webinstaller.yml.</li> </ol>"},{"location":"StatusLED-BlinkCodes/","title":"Board status LED (blink codes)","text":"<p>This page lists possible blink codes of the red LED located on the ESP32-CAM board, their meaning and possible solutions.</p> <p>The error code source definition can be found here.</p>"},{"location":"StatusLED-BlinkCodes/#general-design-approach","title":"General design approach:","text":"<ul> <li>250ms blink code to identify source</li> <li>500ms defined LED off</li> <li>250ms blink code to identify error / status code</li> <li>1,5s defined LED off to signal repetition</li> <li>Repetition blink code: infinite for critical errors and status indication or 2x for warning indication</li> <li>e.g. 3x blinks | 500ms LED off | 2x blinks --&gt; error: SD card not found</li> </ul> source source  blink count error / warning / status status  blink count repeat  infinite WLAN_CONN 1 Disconnected (No Access Point) 1 WLAN_CONN 1 Disconnected (Authentication failure) 2 WLAN_CONN 1 Disconnected (Timeout) 3 WLAN_CONN 1 Disconnected (further reasons) 4 WLAN_INIT 2 WLAN.ini empty or not readable 1 X WLAN_INIT 2 SSID or password empty 2 X WLAN_INIT 2 WIFI init error (details console) 3 X SDCARD_INIT 3 SD card filesystem mount failed 1 X SDCARD_INIT 3 SD card not found (0x107) 2 X SDCARD_INIT 3 SD card init failed (details console) 3 X SDCARD_CHECK 4 Basic check: file creation/write error 1 X SDCARD_CHECK 4 Basic check: file read/CRC error 2 X SDCARD_CHECK 4 Basic check: file delete error 3 X SDCARD_CHECK 4 Basic check: folder/file presence 4 X CAM_INIT 5 Camera init failed (details console) 1 X CAM_INIT 5 Camera framebuffer check failed 2 PSRAM_INIT 6 RAM init failed: Not found/defective 1 X PSRAM_INIT 6 External SPI RAM &lt; 4MB 2 X PSRAM_INIT 6 Total heap &lt; 4MB 3 X TIME_CHECK 7 Missing time sync (check every round) 1 OTA_OR_AP 8 OTA process ongoing 1 X OTA_OR_AP 8 Soft AP started (for remote config) 2 X FLASHLIGHT N/A LED on when flashlight is on solid,  no blink"},{"location":"StatusLED-BlinkCodes/#error-warning","title":"ERROR / WARNING","text":""},{"location":"StatusLED-BlinkCodes/#source-wlan_conn-wlan-disconnected","title":"Source WLAN_CONN: WLAN disconnected","text":"<p>Note</p> <p>Only warning indication, blink code repetition: 2x --&gt; General info: WLAN disconnect reason code description</p>"},{"location":"StatusLED-BlinkCodes/#wlan-disconnected-no-access-point","title":"<code>WLAN disconnected (No Access Point)</code>","text":"<p>WLAN connection is interrupted due to no access point in range.</p>"},{"location":"StatusLED-BlinkCodes/#wlan-disconnected-authentication-failure","title":"<code>WLAN Disconnected (Authentication failure)</code>","text":"<p>WLAN connection is interrupted due to an authentication failure. If error repeats check WLAN config in WLAN.INI (username, password)</p>"},{"location":"StatusLED-BlinkCodes/#wlan-disconnected-timeout","title":"<code>WLAN Disconnected (Timeout)</code>","text":"<p>WLAN connection is interrupted due to an timeout because no beacon from AP is received in a timely manner. Most probably access point  is not available anymore or connection is not reliable.</p>"},{"location":"StatusLED-BlinkCodes/#wlan-disconnected-further-reasons","title":"<code>WLAN Disconnected (Further reasons)</code>","text":"<p>WLAN connection is interrupted due to further reasons. Disconnect reason is printed in warining message. Please check serial console output or logfile from sd card (using another device to retrieve logfile /sdcard/log/message/). Please refer to this page to have additional infos in terms of WLAN disconnect reasons --&gt; WLAN disconnect reason code description</p>"},{"location":"StatusLED-BlinkCodes/#source-wlan_init-wlan-initialization","title":"Source WLAN_INIT: WLAN initialization","text":"<p>Note</p> <p>All critical errors, regular boot not possible</p>"},{"location":"StatusLED-BlinkCodes/#wlanini-empty-or-not-readable","title":"<code>WLAN.ini empty or not readable</code>","text":"<p>The WLAN.INI file is present but content is either not readable or no content present. Please check for further errors in terms of SD card readability or content of WLAN.INI which is located in /sdcard (most top folder od SD card) </p>"},{"location":"StatusLED-BlinkCodes/#ssid-or-password-empty","title":"<code>SSID or password empty</code>","text":"<p>The mandatory parameters SSID (name of WIFI network) and / or password is empty. Please configure those parameters in WLAN.INI and try again.</p>"},{"location":"StatusLED-BlinkCodes/#wifi-init-error-details-console","title":"<code>WIFI init error (details console)</code>","text":"<p>A general WIFI initialization error occured. Please check serial console output or logfile from sd card (using another device to retrieve logfile /sdcard/log/message/) </p>"},{"location":"StatusLED-BlinkCodes/#source-sdcard_init-sd-card-initialization","title":"Source SDCARD_INIT: SD card initialization","text":"<p>Note</p> <p>All critical errors, regular boot not possible</p>"},{"location":"StatusLED-BlinkCodes/#sd-card-filesystem-mount-failed","title":"<code>SD card filesystem mount failed</code>","text":"<p>Failed to mount FAT filesystem on SD card. Check SD card filesystem (only FAT supported) or try another card. Possible further infos: Please check serial console output.</p>"},{"location":"StatusLED-BlinkCodes/#sd-card-not-found-error-code-0x107","title":"<code>SD card not found (Error code 0x107)</code>","text":"<p>SD card init failed. Check if SD card is properly inserted into SD card slot or try another card. Possible further infos: Please check serial console output.</p>"},{"location":"StatusLED-BlinkCodes/#sd-card-init-failed-details-console","title":"<code>SD card init failed (details console)</code>","text":"<p>A general SD card initialization error occured. Please check serial console output.</p>"},{"location":"StatusLED-BlinkCodes/#source-sdcard_check-sd-card-basic-check","title":"Source SDCARD_CHECK: SD card basic check","text":"<p>Note</p> <p>All critical errors, normal boot not possible. Reduced WebUI is going to be loaded for further diagnostic possibilities or redo firmware update.</p>"},{"location":"StatusLED-BlinkCodes/#file-creation-write-error","title":"<code>File creation / write error</code>","text":"<p>A basic check of SD card is performed at boot. Failed to create the test file or writing content to the file failed. Most likely SD card is defective or not supported. Please check logs with log viewer in reduced web interface, serial console output or try another card.</p> <p>Recommendation: Format or try another card</p>"},{"location":"StatusLED-BlinkCodes/#file-read-crc-verfication-error","title":"<code>File read / CRC verfication error</code>","text":"<p>A basic check of SD card is performed at boot. Failed to read the test file or CRC of read back content failed. Most likely SD card is defective. Please check logs with log viewer in reduced web interface or serial console output for further error indication or try another card.</p> <p>Recommendation: Format or try another card</p>"},{"location":"StatusLED-BlinkCodes/#file-delete-error","title":"<code>File delete error</code>","text":"<p>A basic check of SD card is performed at boot. Failed to delelte the test file. Most likely SD card is defective. Please check logs with log viewer in reduced web interface or serial console output for further error indication or try another card.</p> <p>Recommendation: Format or try another card</p>"},{"location":"StatusLED-BlinkCodes/#folder-file-presence-failed","title":"<code>Folder / File presence failed</code>","text":"<p>A basic check of SD card is performed at boot. One or more menadatory folder / file are not found on SD card. Please check logs with log viewer in reduced web interface or serial console output for further error indication.</p> <p>Recommendation: Repeat installation using AI-on-the-edge-device__update__*.zip</p>"},{"location":"StatusLED-BlinkCodes/#source-cam_init-camera-initialization","title":"Source CAM_INIT: Camera initialization","text":""},{"location":"StatusLED-BlinkCodes/#camera-init-failed-details-console","title":"<code>Camera init failed (details console)</code>","text":"<p>Note</p> <p>Critical error, normal boot not possible. Reduced WebUI is going to be loaded for further diagnostic possibilities or redo firmware update.</p> <p>A general camera initialization error occured. Please check logs with log viewer in reduced web interface or serial console output for further error indication.</p> <p>Recommendation: Check for proper electrical connection, whether camera model is supported and whether power supply is sufficient.</p>"},{"location":"StatusLED-BlinkCodes/#camera-framebuffer-check-failed","title":"<code>Camera framebuffer check failed</code>","text":"<p>The framebuffer of the camera was not readable. The firmware will trying to continue regular boot, but further errors can occur which block regular processing. Please check logs with logfile viewer if processing is behaving irregular.</p> <p>Recommendation: Check for proper electrical commenection, wether camera model is supported and wether power supply is suffcient.</p>"},{"location":"StatusLED-BlinkCodes/#source-psram_init-external-ram-spi-ram-initialization","title":"Source PSRAM_INIT: External RAM (SPI RAM) initialization","text":"<p>Note</p> <p>A critical errors, normal boot not possible. Reduced WebUI is going to be loaded for further diagnostic possibilities or redo firmware update.</p>"},{"location":"StatusLED-BlinkCodes/#spi-ram-init-failed-not-founddefective","title":"<code>SPI RAM init failed: Not found/defective</code>","text":"<p>External RAM (SPI RAM) initialization failed. Most likely external RAM not accessable or defective. Normal operation is not possible without having external RAM.</p>"},{"location":"StatusLED-BlinkCodes/#external-spi-ram-4mb","title":"<code>External SPI RAM &lt; 4MB</code>","text":"<p>External RAM (SPI RAM) initialization successful, but external RAM size is too small. A size of &gt;= 4MB is necessary to run this firmware. </p>"},{"location":"StatusLED-BlinkCodes/#total-heap-4mb","title":"<code>Total heap &lt; 4MB</code>","text":"<p>Total available system memory (heap) is too small. A size of &gt;= 4MB is necessary to run this firmware. </p>"},{"location":"StatusLED-BlinkCodes/#source-time_check-external-ram-spi-ram-initialization","title":"Source TIME_CHECK: External RAM (SPI RAM) initialization","text":""},{"location":"StatusLED-BlinkCodes/#missing-time-sync-check-every-round","title":"<code>Missing time sync (check every round)</code>","text":"<p>Note</p> <p>Only warning indication, blink code repetition: 2x</p> <p>If system is configured to be synced with a NTP server the sync status is checked after every round (in state: \"Flow finished\". An warming message is also printed to log). If the time is not synced after serveral rounds, please check for proper configuration.</p>"},{"location":"StatusLED-BlinkCodes/#status","title":"STATUS","text":"<p>Note</p> <p>All only status indication</p>"},{"location":"StatusLED-BlinkCodes/#source-ota_or_ap-ota-update-access-point-mode","title":"Source OTA_OR_AP: OTA Update / Access point mode","text":""},{"location":"StatusLED-BlinkCodes/#ota-process-ongoing","title":"<code>OTA process ongoing</code>","text":"<p>An OTA is performed right now. Please wait until OTA is completed. System is rebooting automatically. If system is not coming up, please check serial console output.</p>"},{"location":"StatusLED-BlinkCodes/#soft-ap-started-for-remote-config","title":"<code>Soft AP started (for remote config)</code>","text":"<p>The built-in access point functionality is started to perform initial remote remote setup. Further description: Installtion --&gt; <code>Section Remote Setup using the built-in Access Point</code></p>"},{"location":"StatusLED-BlinkCodes/#source-flashlight-flashlight","title":"Source FLASHLIGHT: Flashlight","text":""},{"location":"StatusLED-BlinkCodes/#led-on-when-flashlight-is-on","title":"<code>LED on when flashlight is on</code>","text":"<p>The LED is solid on as long the flashlight is on. This feature has lower priority than the other LED codes. Whenever another code occurs this feature will be overrided.</p>"},{"location":"Testing/","title":"Testing Option for VSCode","text":"<p>You can test your functions directly on the device. </p>"},{"location":"Testing/#structure","title":"Structure","text":"<p>All tests are under directory \"test\" in the project and not compiled with default build option of platformio. The main function is in file <code>test_suite_controlflow.cpp</code>. In method <code>app_main()</code> you can add your own tests. </p> <p></p>"},{"location":"Testing/#include-my-my-own-test","title":"Include my my own test","text":"<p>In method <code>app_main()</code> of <code>test_suite_controlflow.cpp</code> you can add your own tests. Include your test-file in the top like</p> <p><code>#include \"components/jomjol-flowcontroll/test_flow_postrocess_helper.cpp\"</code></p> <p>components is a subfolder of tests here. Not the components directory of root source.</p> <p>In the bottom add your test function.</p> <p><code>RUN_TEST(testNegative);</code></p> <p>Your test function should have a <code>TEST_ASSERT_EQUAL_*</code>. For more information look at unity-testing. </p>"},{"location":"Testing/#run-tests","title":"Run tests","text":"<p>You will need a testing device. best with usb adapter. Before you upload your tests you will need to setup the device with initial setup procedure described in [[Installation]]</p> <p></p> <p>Now you can use Visual Studio Code or a standard console to upload the test code. In VS Code (tab platformio) open Advanced and select Test.</p> <p></p> <p>Alternatively you can run it in console/terminal with <code>platformio test --environment esp32cam</code>.</p> <p>In my environment the serial terminal not opens. I have to do it for myself. You will see much logging. If any test fails it logs it out. Else it logs all test passed in the end.</p>"},{"location":"Testing/#troubleshooting","title":"Troubleshooting","text":"<p>If you test very much cases in one function, the device runs in Stack Overflow and an endless boot. Reduce the count of test cases or split the test function in multiple functions.</p>"},{"location":"Upload-files-by-script/","title":"Scripted File Upload","text":"<p>To upload a file e.g. using <code>curl</code>, you first have to delete it and then upload it:</p> <pre><code>curl -d '' http://192.168.1.153/delete/html/index.html\ncurl --data-binary @ota_page.html http://192.168.1.153/upload/html/index.html\n</code></pre>"},{"location":"WLAN-disconnect-reason/","title":"WLAN disconnect reasons","text":"<p>In the logfile the WLAN disconnect reason code are printed whenever a disconnect event occurs (WARNING LEVEL or higher).</p> <p>Further information and additional description of reason codes can be found here: WLAN disconnect reason code description</p>"},{"location":"Watermeter-specific-analog---digital-transition/","title":"Analog/Digital Transition on Water Meters","text":"<p>At first, for the most water meters the default configuration should be work. But the digit, especially the last digit differs in some devices.</p>"},{"location":"Watermeter-specific-analog---digital-transition/#normal-transition","title":"\"Normal\" transition","text":"<p>In most cases, the transition of the last digit starts when the analogue pointer is &gt; 9. </p> <p>Often the last digit \"hangs\" a bit on this devices and comes not over zero. So it is not easy to see which digit is correct. In the first example 4 or still 3? (3 is correct).</p> <p> </p>"},{"location":"Watermeter-specific-analog---digital-transition/#early-transition","title":"Early transition","text":"<p>Some units start the transition very early or run with the analogue pointer. In the third example, is it a 3 or a 2?</p> <p> </p>"},{"location":"Watermeter-specific-analog---digital-transition/#inaccuracies-in-image-recognition","title":"Inaccuracies in image recognition","text":"<p>The models for image recognition are good, but have inaccuracies in the range +/- 0.2. In order to obtain as many correct results as possible, a treatment is carried out in the post process in the range of 9.8-0.2 for the analogue pointer, which must start differently depending on the type of counter.</p>"},{"location":"Watermeter-specific-analog---digital-transition/#how-to-configure-for-my-meter-type","title":"How to configure for my meter type","text":"<p>If you have a devices with \"normal\" transition you should not have any issues. On devices with \"early\" transition, you can set the option <code>AnalogDigitalTransitionStart</code> to a value between 6 and 8.</p>"},{"location":"collect-new-images/","title":"Collect images to improve the models","text":"<p>If your device has new, different digits or pointers it might be that the existing models don't recognize them well. In such case you can collect your images and so we can train the model better. This helps you and also others as the models get more accurate. Adding more images also helps if you have a model that is already known, but the neural models do not produce good results.</p> <p>Experienced users can do the training also by themselves, see Learn a model with your own images. </p>"},{"location":"collect-new-images/#before-you-start","title":"Before you start","text":"<p>Before you go ahead, please check if your digits/pointers are not yet contained in the training data. A visual overview is available at digits resp. pointers.</p> <p>Poor recognition is often caused by blurred images, low contrast or incorrect setting of the ROIs. Therefore, check these possibilities first, as additional training will bring little improvement here. See ROI Configuration for details.</p>"},{"location":"collect-new-images/#collecting-images","title":"Collecting images","text":"<p>The neural network is trained based on a set of images that have already been collected over time. If your digits are included or at least very similar to included images, the chance is very high that the neural network is working fine for you as well.</p> <p>The neural network configuration is stored in the TensorFlow Lite format as <code>*.tfl</code> or <code>*.tflite</code> in the <code>/config</code> directory on the SD card. A model can be updated (or a new one added) by uploading the new file and activating it on the configuration page or in the config file <code>/config/config.ini</code>.</p> <p>In order to incorporate new digits a training set of images is required. The training images needs to be collected in the final setup with the help of the <code>Digits</code> or <code>Analog</code> log settings (not to be confused with the <code>Data</code> or <code>Debug</code> log). Enable the logging of the images on the configuration page or in the config file <code>/config/config.ini</code>:</p> <p></p> <p>Now be patient! You have to wait until it has collected an image of each digit of every type. They will be placed on the SD card in the folder <code>/log/digit/</code> resp. <code>/log/analog/</code>.</p> <p>After some days, there will be a lot of images, many of them very similar. Because of this, it is important to select only a subset of them for the model training.</p> <p>The tools shown below can help you with that.</p>"},{"location":"collect-new-images/#collecting-images-for-dig-class100dig-contana-class100","title":"Collecting images for dig-class100/dig-cont/ana-class100","text":"<p>For digits use Collectmeterdigits resp. for pointers use collectmeteranalog to fetch the images from the device and select a subset of them. Please read the detailed instructions on the mentioned links for details!</p> <p>If the fetching of the images is too slow for you, a faster way to get the images to your PC is to remove the SD-card from the ESP32 module and insert it into the card reader of yur PC. Then search for two..three images of each digit (not more! :-)). You will have to make sure to label the images yourself matching the effective value they are supposed to show. </p>"},{"location":"collect-new-images/#share-your-images","title":"Share your images","text":"<p>In most cases we will integrate your images in the training dataset of the models. Only if we fear a degradation of the models or you need a different behavior, we might not include the data in the standard models (see at bottom of page for reasons).</p> <p>To provide your images to us for training the model, open an Github Issue and append the zipped images ito it.</p>"},{"location":"collect-new-images/#images-can-be-rejected-if","title":"Images can be rejected if","text":"<ul> <li>You provide too many images. More than 1000 images of your device are really to much. </li> <li>Images which are not good enough (see ROI Configuration) will be rejected. It would reduce the accuracy of the networks.</li> <li>Images with too little focus will be rejected. </li> <li>Images with too much blur are rejected.</li> </ul> <p>Our models are to small to recognize everything in any quality. So we use only images of medium or good quality.</p>"},{"location":"data-logging/","title":"Data Logging","text":"<p>When Data Logging is enabled (See parameter <code>DataLogActive</code>), the results of every round gets written to the SD-Card.</p> <p>The data files are stored in <code>/log/data</code> on the SD-Card.</p>"},{"location":"data-logging/#data-format","title":"Data Format","text":"<p>The data is stored as CSV with the following columns: <code>time</code>, <code>name-of-number</code>, <code>raw-value</code>, <code>return-value</code>, <code>pre-value</code>, <code>change-rate</code>, <code>change-absolute</code>, <code>error-text</code>, <code>cnn-digital</code>, <code>cnn-analog</code></p>"},{"location":"initial-setup/","title":"Initial Setup","text":"<p>After setting up the device (firmware, SD card, WLAN) the device will connect to the wifi access point and start in an initial setup configuration:</p> <p></p> <p>With the buttons on the top you can navigate through 5 steps which guide you through the necessary setup:</p> <ol> <li>Create the Reference Image. It is the base for the position referencing and the identification of the digits and counters.</li> <li>Define two unique Reference Marks. They is used to align the individual camera images and identify the absolute positions.</li> <li>Define ROIs for the Digits. They will be used to digitize the digit part of your meter. If your meter has no digits, this step can be skipped.</li> <li>Define ROIs for the Analog Counters. (Only required in case your meter has analog counters)</li> <li>General Settings. Further configuration of your device.</li> </ol> <p>All settings can be accessed later in the normal operation mode.</p> <p>Note</p> <p>Don't forget to save each step with \"Save\", and do not reboot at this stage.</p>"},{"location":"initial-setup/#finish-the-setup-and-change-to-the-normal-operation-mode","title":"Finish the Setup and change to the Normal Operation mode","text":"<p>With the last step <code>(1)</code> you leave the Setup Mode and reboot to the Normal Operation mode.</p> <p></p>"},{"location":"initial-setup/#access-to-the-setup-pages-in-the-normal-operation-mode","title":"Access to the Setup Pages in the Normal Operation mode","text":"<p>You always can access all the settings during the normal operation mode via the <code>Settings</code> menu:</p> <p></p> <ul> <li><code>(1)</code> Access to the General Settings.</li> <li><code>(2)</code> Update of the Reference Image.</li> <li><code>(3)</code> Update of the Alignment Marks.</li> <li><code>(4)/(5)</code> Update of the ROIs.</li> </ul>"},{"location":"ota/","title":"Over-The-Air (OTA) Update","text":"<p>You can do an OTA (over-the-air) update via the Web Interface. Grab the firmware from the</p> <ul> <li>Releases page (Stable, tested versions), or the</li> <li>Automatically build development branch (experimental, untested versions). Please inform yourself on Living on the Edge first!</li> </ul>"},{"location":"ota/#update-procedure","title":"Update Procedure","text":"<ol> <li>Create a backup of your configuration. Either use the Backup/Restore function of your device for this (menu <code>System &gt; Backup/Restore</code>) or back the files manually up using the File Server (menu <code>File Server</code>, folder <code>config</code>). It is recommended to at least save the config file <code>config.ini</code>!</li> <li>Head to the menu <code>System &gt; OTA Update</code> and follow the instructions there.</li> </ol> <p>If you do an update between major versions, it might be needed to modify the config file <code>config.ini</code> as it's syntax or context has changed. To do so, go to the menu <code>Settings &gt; Configuration</code> (after the update completed and the device restarted) and check if it warns you about an unset parameter.</p>"},{"location":"ota/#update-from-version-v1200-or-newer","title":"Update from version <code>v12.0.0</code> or newer","text":"<p>You can use the over the air update mechanism, which uploads the update via a ZIP files.</p> <p>The update file is located on the release page. Please choose the zip file with the following naming: <code>AI-on-the-edge-device__update__*.zip</code></p> <p>Go to the menu <code>System --&gt; OTA Update</code> and follow the instructions there. After a final automatic reboot you should have the new version running.</p>"},{"location":"ota/#update-from-version-older-than-v1200","title":"Update from version older than <code>v12.0.0</code>","text":"<p>If you update from an version older than 12.0.1, you should firstly update to version 12.0.1. Background are not fully backward compatible changes in the <code>config.ini</code>, that are taken care of in this version.</p> <p>Warning</p> <p>Make sure to read the instructions below carefully!</p> <ol> <li> <p>Backup your configuration (use the <code>System -&gt; Backup/Restore</code> page)!</p> </li> <li> <p>Upload and update the <code>update-*.zip</code> file from the release  <code>12.0.1</code> see here .</p> </li> <li> <p>Let it restart and check on the <code>System -&gt; Info</code> page that the Firmware as well as the Web UI got updated. If only one got updated, redo the update. If it fails several times, you also can update the Firmware and the Web UI separately.</p> </li> <li> <p>Safe way: </p> <ol> <li>Update first the <code>firmware.bin</code> (extract it from one of the provided zip files) and do the Reboot</li> <li>Update with the full zip file (<code>update-*.zip</code>, ignore the version warning after the reboot)</li> </ol> </li> <li> <p>Please go to <code>Settings -&gt; Configuration</code> and address the changed parameters:</p> <ul> <li>DataLogging (storing the values for data graph)</li> <li>Debug (extended by different debug reporting levels)</li> </ul> </li> <li> <p>Make sure it starts to do the digitalization (check the Error field on the overview page). If it does not start a round within a minute, restart the device.</p> </li> </ol> <p>Note</p> <p>If the system is working now without any issues, please open the configuration editor once and save the <code>config.ini</code>. This will update the file to the newest content.</p> <p>Now you can safely update to the newest version.</p>"},{"location":"outdated--Integrated-Functions/","title":"Integrated Functions","text":"<p>Warning</p> <p>This page no longer is maintained!</p>"},{"location":"outdated--Integrated-Functions/#wasserzaehler","title":"wasserzaehler","text":"<p><code>http://IP-ESP32/wasserzaehler.html</code></p> <p>This is the main purpose of this device. It returns the converted image as a number with different option. The output can be modified either by the configuration parameters or by HTML parameters.</p> <p>Details can be found here:  tbd</p>"},{"location":"outdated--Integrated-Functions/#picture-server","title":"Picture Server","text":"<p><code>http://IP-ESP32/capture</code></p> <p><code>http://IP-ESP32/capture_with_flashlight</code></p> <p>This is a implementation of the camera interface of https://github.com/jomjol/water-meter-picture-provider</p> <p>It is fully compatible including the parameters (<code>quality</code>=..., <code>size=...</code> ) . This allows to use this ESP32 system in parallel to the corresponding docker system: https://github.com/jomjol/water-meter-system-complete, from which this project is basically the successor.</p>"},{"location":"outdated--Integrated-Functions/#file-server","title":"File server","text":"<p>Access: <code>http://IP-ESP32/fileserver/</code></p> <p>Simple file server, that allows viewing, upload, download and deleting of single files of the SD-card content.</p> <p>The usage is self explaining. The file path or file can directly be accessed by the URL after file server.</p> <p>Example for <code>config.ini</code> :  <code>http://IP-ESP/fileserver/config/config.ini</code></p>"},{"location":"outdated--Integrated-Functions/#ota-update","title":"OTA-Update","text":"<p><code>http://IP-ESP32/ota?file=firmware.bin</code></p> <p>Here an over the air update can be triggered. The firmware file is expected to be located in the sub directory <code>/firmware/</code> and can be uploaded with the file server. By the parameter <code>file</code> the name of the firmware file needs to be given.</p>"},{"location":"outdated--Integrated-Functions/#reboot","title":"Reboot","text":"<p><code>http://IP-ESP32/reboot</code></p> <p>A reboot with a delay of 5 seconds is initiated, e.g. after firmware update.</p> <p>ATTENTION: currently this is not working properly - hardware power off is needed instead. Work in progress!</p>"},{"location":"outdated--Integrated-Functions/#simple-web-server","title":"Simple Web Server","text":"<p>If none of the above URLs are fitting, a very simple web server checks, if there is a fitting file from the sub directory <code>/html</code>  This can be used for a very simple web server for information or simple web pages.</p>"},{"location":"prometheus-openmetrics/","title":"Prometheus/OpenMetrics","text":"<p>A set of metrics is exported via the <code>/metrics</code> REST API path on the device. Besides the current value, a set of device properties are exported. Multiple sequences (aka numbers) are supported via a label. The metrics are provided in text wire format.</p> <p>Example:</p> <pre><code>$ curl http://&lt;IP&gt;/metrics\n# HELP ai_on_the_edge_device_flow_value current value of meter readout\n# TYPE ai_on_the_edge_device_flow_value gauge\nai_on_the_edge_device_flow_value{sequence=\"main\"} 240.7064\n# HELP ai_on_the_edge_device_cpu_temperature_celsius current cpu temperature in celsius\n# TYPE ai_on_the_edge_device_cpu_temperature_celsius gauge\nai_on_the_edge_device_cpu_temperature_celsius 41\n# HELP ai_on_the_edge_device_rssi_dbm current WiFi signal strength in dBm\n# TYPE ai_on_the_edge_device_rssi_dbm gauge\nai_on_the_edge_device_rssi_dbm -67\n# HELP ai_on_the_edge_device_memory_heap_free_bytes available heap memory\n# TYPE ai_on_the_edge_device_memory_heap_free_bytes gauge\nai_on_the_edge_device_memory_heap_free_bytes 716303\n# HELP ai_on_the_edge_device_uptime_seconds device uptime in seconds\n# TYPE ai_on_the_edge_device_uptime_seconds gauge\nai_on_the_edge_device_uptime_seconds 214267\n# HELP ai_on_the_edge_device_rounds_total data aquisition rounds since device startup\n# TYPE ai_on_the_edge_device_rounds_total counter\nai_on_the_edge_device_rounds_total 239\n</code></pre>"},{"location":"prometheus-openmetrics/#prometheus-scrape-config","title":"Prometheus Scrape Config","text":"<p>The following scrape config (add to <code>prometheus.yml</code>) can be used as an example to ingest available metrics with prometheus:</p> <pre><code>scrape_configs:\n  - job_name: watermeter\n    scrape_interval: 300s\n    metrics_path: /metrics\n    static_configs:\n      - targets: ['&lt;IP&gt;']\n</code></pre>"},{"location":"prometheus-openmetrics/#references","title":"References","text":"<ul> <li>OpenMetrics</li> </ul>"},{"location":"rolling-installation/","title":"Living on the Edge","text":"<p>The Github repository contains multiple branches:</p> <ul> <li>The master branch contains the same firmware version as provided on the release page.</li> <li>The rolling branch contains the latest version of the Firmware and the Web Interface. It might already contain a fix for your issue. But it is work in progress, don't expect it to work stable or be an improvement for your AI-on-the-edge-device! Also it might break the OTA Update and thus require manual flashing over USB!</li> <li>Any other branch is used to develop a feature or fix, only use them when you know what it is about!</li> </ul>"},{"location":"rolling-installation/#i-still-want-to-try-it","title":"I still want to try it","text":"<p>Ok, then grab the latest <code>rolling</code> build from Github Actions Page and proceed as following:</p> <ol> <li>Pick the most top successful (green) build:    </li> <li>Scroll down and download the <code>AI-on-the-edge-device__update__*.zip</code>:    </li> <li>Flash the zip file using the OTA Update page of your device.</li> </ol>"}]}